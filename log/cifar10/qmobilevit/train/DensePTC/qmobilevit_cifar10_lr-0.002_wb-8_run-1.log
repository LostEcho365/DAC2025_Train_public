/home/xinyuzh/anaconda3/envs/timm/lib/python3.11/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
[38;21m2024-11-12 21:37:22,903 - train.py[line:234] - INFO: dataset:
  name: cifar10
  root: /home/xinyuzh/workspace/dataset/DAC2025_Train_public/cifar10
  train_valid_split_ratio: [0.9, 0.1]
  train_valid_split_seed: 1
  resize_mode: bicubic
  center_crop: 32
  n_test_samples: None
  n_valid_samples: None
  num_workers: 2
  img_height: 32
  img_width: 32
  in_channels: 3
  num_classes: 10
  transform: augmented
  shuffle: 0
  augment: None
criterion:
  name: ce
aux_criterion: None
optimizer:
  name: adamw
  lr: 0.002
  weight_decay: 0.0001
  grad_clip_value: 0
scheduler:
  name: cosine
  lr_gamma: 0.99
  lr_min: 2e-05
run:
  experiment: cifar10_qmobilevitmoe_train
  n_epochs: 200
  batch_size: 64
  use_cuda: 1
  gpu_id: 0
  deterministic: 22
  random_state: 42
  log_interval: 200
  train_noise: 0
  grad_clip: False
  max_grad_value: 1
  do_distill: False
  compile: False
quantize:
  weight_bit: 8
  input_bit: 8
noise:
  phase_bias: 0
  phase_noise_std: 0
  gamma_noise_std: 0
  crosstalk_factor: 0
  random_state: 42
  weight_noise_std: 0.0
  output_noise_std: 0
  crosstalk_flag: False
  noise_flag: False
  light_redist: False
  input_power_gating: False
  input_modulation_ER: 6
  output_power_gating: False
  crosstalk_scheduler:
    interv_h: 20
    interv_v: 120
    interv_s: 9
    ps_width: 6
checkpoint:
  save_best_model_k: 3
  checkpoint_dir: cifar10/qmobileViTMoE/train
  model_comment: lr-0.0020_wb-8_run-1
  resume: 0
  restore_checkpoint: 
  no_linear: 0
model:
  name: QMobileViT
  conv_cfg:
    type: QConv2d
    w_bit: 8
    in_bit: 8
    out_bit: 8
  linear_cfg:
    type: QLinear
    w_bit: 8
    in_bit: 8
    out_bit: 8
  norm_cfg:
    type: BN2d
    affine: True
  act_cfg:
    type: ReLU6
    inplace: True
  dim: [48, 64, 80]
  depth: [2, 3, 2]
  channels: [16, 16, 24, 24, 32, 32, 48, 48, 64, 64, 256]
  expansion: 2
  is_moe: True
  expert_num: 8
  top_k: 2
  matmul_cfg:
    type: QMatMul
    w_bit: 8
    in_bit: 8
    out_bit: 8
debug:
  verbose: 1
  verboise: 1
dst_scheduler: None[0m
[38;21m2024-11-12 21:37:29,214 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,302 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,427 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,442 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,443 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,452 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,453 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,457 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,459 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,460 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,461 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,493 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,493 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,494 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,495 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,496 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,496 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,497 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,498 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,499 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,502 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,503 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,503 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,505 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,506 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,506 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,507 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,507 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,508 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,509 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,510 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,511 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,511 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,512 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,513 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,513 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,514 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,515 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,518 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,518 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,519 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,521 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,522 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,522 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,527 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,535 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,536 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,546 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,547 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,548 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,548 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,561 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,561 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,562 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,619 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,620 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,620 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,621 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,622 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,622 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,670 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,670 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,671 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,672 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,672 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,673 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,673 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,674 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,674 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,675 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,675 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,676 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,677 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,677 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,681 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,681 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,682 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,682 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,683 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,684 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,684 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,685 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,685 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,686 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,686 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,687 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,687 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,688 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,688 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,689 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,690 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,690 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,691 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,691 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,692 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,692 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,693 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,693 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,694 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,694 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,695 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,695 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,696 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,697 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,697 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,698 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,698 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,699 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,701 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,701 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,702 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,703 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,703 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,704 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,704 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,705 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,706 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,706 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,707 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,708 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,708 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,709 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,709 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,710 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,711 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,711 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,712 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,713 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,713 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,714 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,715 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,715 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,716 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,716 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,717 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,718 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,718 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,718 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,719 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,720 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,720 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,721 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,721 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,722 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,722 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,723 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,723 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,724 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,725 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,725 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,726 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,726 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,727 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,728 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,728 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,728 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,729 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,730 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,730 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,731 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,731 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,732 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,735 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,736 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,745 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,746 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,746 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,747 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,748 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,749 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,749 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,750 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,750 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,752 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,752 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,753 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,755 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,755 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,756 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,757 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,758 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,758 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,759 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,760 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,760 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,761 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,762 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,763 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,763 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,764 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,764 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,765 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,765 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,766 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,766 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,767 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,767 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,768 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,768 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,769 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,769 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,771 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,771 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,772 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,772 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,773 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,773 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,774 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,774 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,775 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,775 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,776 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,776 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,777 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,778 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,778 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,780 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,780 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,781 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,781 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,782 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,782 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,783 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,784 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,794 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,795 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,795 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,796 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,797 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,797 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,799 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,800 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,800 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,801 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,802 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,802 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,803 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,804 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,804 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,808 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,809 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,810 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,811 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,812 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,813 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,814 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,815 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,815 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,816 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,816 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,817 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,818 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,821 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,822 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,822 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,823 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,824 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,824 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,825 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,825 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,829 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,830 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,830 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,831 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,831 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,832 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,832 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,834 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,834 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,835 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,835 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,836 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,836 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,837 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,838 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,838 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,839 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,839 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,841 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,841 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,842 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,843 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,844 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,845 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,846 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,847 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,847 - utils.py[line:966] - INFO: LSQ Weight quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: False[0m
[38;21m2024-11-12 21:37:29,848 - utils.py[line:831] - INFO: LSQ Act quantizer: (mode: tensor_wise): initialize weight scale for int8 quantization with offset: True[0m
[38;21m2024-11-12 21:37:29,850 - train.py[line:270] - INFO: QMobileViT(
  (conv1): ConvBlock(
    (conv): QConv2d(
      3, 16, kernel_size=(3, 3), stride=(2, 2), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
      (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
      (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
      (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
    )
    (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU6(inplace=True)
  )
  (mobvit_blocks): Sequential(
    (0): InvertedResidual(
      (conv): Sequential(
        (0): ConvBlock(
          (conv): QConv2d(
            16, 32, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (1): ConvBlock(
          (conv): QConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (2): ConvBlock(
          (conv): QConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (1): InvertedResidual(
      (conv): Sequential(
        (0): ConvBlock(
          (conv): QConv2d(
            16, 32, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (1): ConvBlock(
          (conv): QConv2d(
            32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (2): ConvBlock(
          (conv): QConv2d(
            32, 24, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (2): InvertedResidual(
      (conv): Sequential(
        (0): ConvBlock(
          (conv): QConv2d(
            24, 48, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (1): ConvBlock(
          (conv): QConv2d(
            48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (2): ConvBlock(
          (conv): QConv2d(
            48, 24, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (3): InvertedResidual(
      (conv): Sequential(
        (0): ConvBlock(
          (conv): QConv2d(
            24, 48, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (1): ConvBlock(
          (conv): QConv2d(
            48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (2): ConvBlock(
          (conv): QConv2d(
            48, 32, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (4): QMobileViTBlock(
      (conv1): ConvBlock(
        (conv): QConv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (conv2): ConvBlock(
        (conv): QConv2d(
          32, 48, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (transformer_layers): ModuleList(
        (0-1): 2 x QTransformerMoEEncoderLayer(
          (self_attn): QAttention(
            Quantized_Attention
            (qkv): LinearBlock(
              (linear): QLinear(
                48, 96, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
            (proj): LinearBlock(
              (linear): QLinear(
                32, 48, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
            (quantized_matmul): MatMulBlock(
              (matmul): QMatMul(
                QuantizedMatMul, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
          )
          (gate): Linear(in_features=48, out_features=8, bias=False)
          (experts): ModuleList(
            (0-7): 8 x MlpExpert(
              (activation): ReLU()
              (linear1): LinearBlock(
                (linear): QLinear(
                  48, 96, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                  (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                  (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                  (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                )
              )
              (dropout): Dropout(p=0.0, inplace=False)
              (linear2): LinearBlock(
                (linear): QLinear(
                  96, 48, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                  (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                  (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                  (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                )
              )
            )
          )
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (conv3): ConvBlock(
        (conv): QConv2d(
          48, 32, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (conv4): ConvBlock(
        (conv): QConv2d(
          64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
    )
    (5): InvertedResidual(
      (conv): Sequential(
        (0): ConvBlock(
          (conv): QConv2d(
            32, 64, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (1): ConvBlock(
          (conv): QConv2d(
            64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (2): ConvBlock(
          (conv): QConv2d(
            64, 48, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (6): QMobileViTBlock(
      (conv1): ConvBlock(
        (conv): QConv2d(
          48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (conv2): ConvBlock(
        (conv): QConv2d(
          48, 64, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (transformer_layers): ModuleList(
        (0-2): 3 x QTransformerEncoderLayer(
          (self_attn): QAttention(
            Quantized_Attention
            (qkv): LinearBlock(
              (linear): QLinear(
                64, 96, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
            (proj): LinearBlock(
              (linear): QLinear(
                32, 64, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
            (quantized_matmul): MatMulBlock(
              (matmul): QMatMul(
                QuantizedMatMul, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
          )
          (linear1): LinearBlock(
            (linear): QLinear(
              64, 256, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
              (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
              (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): LinearBlock(
            (linear): QLinear(
              256, 64, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
              (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
              (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            )
          )
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU()
        )
      )
      (conv3): ConvBlock(
        (conv): QConv2d(
          64, 48, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (conv4): ConvBlock(
        (conv): QConv2d(
          96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
    )
    (7): InvertedResidual(
      (conv): Sequential(
        (0): ConvBlock(
          (conv): QConv2d(
            48, 96, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (1): ConvBlock(
          (conv): QConv2d(
            96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU6(inplace=True)
        )
        (2): ConvBlock(
          (conv): QConv2d(
            96, 64, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
            (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
            (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          )
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (8): QMobileViTBlock(
      (conv1): ConvBlock(
        (conv): QConv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (conv2): ConvBlock(
        (conv): QConv2d(
          64, 80, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (transformer_layers): ModuleList(
        (0-1): 2 x QTransformerEncoderLayer(
          (self_attn): QAttention(
            Quantized_Attention
            (qkv): LinearBlock(
              (linear): QLinear(
                80, 96, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
            (proj): LinearBlock(
              (linear): QLinear(
                32, 80, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
            (quantized_matmul): MatMulBlock(
              (matmul): QMatMul(
                QuantizedMatMul, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
                (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
                (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
                (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              )
            )
          )
          (linear1): LinearBlock(
            (linear): QLinear(
              80, 320, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
              (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
              (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): LinearBlock(
            (linear): QLinear(
              320, 80, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
              (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
              (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
              (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
            )
          )
          (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU()
        )
      )
      (conv3): ConvBlock(
        (conv): QConv2d(
          80, 64, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
      (conv4): ConvBlock(
        (conv): QConv2d(
          128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
          (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
          (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
          (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
        )
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU6(inplace=True)
      )
    )
  )
  (conv_last): ConvBlock(
    (conv): QConv2d(
      64, 256, kernel_size=(1, 1), stride=(1, 1), in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
      (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
      (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
      (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
    )
    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU6(inplace=True)
  )
  (pool): AdaptiveAvgPool2d(output_size=1)
  (final_layer): LinearBlock(
    (linear): QLinear(
      256, 10, in_bits=8, w_bits=8, out_bits=8, input_noise_std=0, weight_noise_std=0, output_noise_std=0
      (input_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
      (weight_quantizer): WeightQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': True, 'offset': False})
      (output_quantizer): ActQuantizer_LSQ({'nbits': 8, 'mode': 'tensor_wise', 'signed': False, 'offset': True})
    )
  )
)[0m
Files already downloaded and verified
Files already downloaded and verified
set weight_decay to 0 for ['conv1.conv.input_quantizer', 'conv1.conv.input_quantizer', 'conv1.conv.weight_quantizer', 'conv1.conv.output_quantizer', 'conv1.conv.output_quantizer', 'conv1.norm', 'mobvit_blocks.0.conv.0.conv.input_quantizer', 'mobvit_blocks.0.conv.0.conv.input_quantizer', 'mobvit_blocks.0.conv.0.conv.weight_quantizer', 'mobvit_blocks.0.conv.0.conv.output_quantizer', 'mobvit_blocks.0.conv.0.conv.output_quantizer', 'mobvit_blocks.0.conv.0.norm', 'mobvit_blocks.0.conv.1.conv.input_quantizer', 'mobvit_blocks.0.conv.1.conv.input_quantizer', 'mobvit_blocks.0.conv.1.conv.weight_quantizer', 'mobvit_blocks.0.conv.1.conv.output_quantizer', 'mobvit_blocks.0.conv.1.conv.output_quantizer', 'mobvit_blocks.0.conv.1.norm', 'mobvit_blocks.0.conv.2.conv.input_quantizer', 'mobvit_blocks.0.conv.2.conv.input_quantizer', 'mobvit_blocks.0.conv.2.conv.weight_quantizer', 'mobvit_blocks.0.conv.2.conv.output_quantizer', 'mobvit_blocks.0.conv.2.conv.output_quantizer', 'mobvit_blocks.0.conv.2.norm', 'mobvit_blocks.1.conv.0.conv.input_quantizer', 'mobvit_blocks.1.conv.0.conv.input_quantizer', 'mobvit_blocks.1.conv.0.conv.weight_quantizer', 'mobvit_blocks.1.conv.0.conv.output_quantizer', 'mobvit_blocks.1.conv.0.conv.output_quantizer', 'mobvit_blocks.1.conv.0.norm', 'mobvit_blocks.1.conv.1.conv.input_quantizer', 'mobvit_blocks.1.conv.1.conv.input_quantizer', 'mobvit_blocks.1.conv.1.conv.weight_quantizer', 'mobvit_blocks.1.conv.1.conv.output_quantizer', 'mobvit_blocks.1.conv.1.conv.output_quantizer', 'mobvit_blocks.1.conv.1.norm', 'mobvit_blocks.1.conv.2.conv.input_quantizer', 'mobvit_blocks.1.conv.2.conv.input_quantizer', 'mobvit_blocks.1.conv.2.conv.weight_quantizer', 'mobvit_blocks.1.conv.2.conv.output_quantizer', 'mobvit_blocks.1.conv.2.conv.output_quantizer', 'mobvit_blocks.1.conv.2.norm', 'mobvit_blocks.2.conv.0.conv.input_quantizer', 'mobvit_blocks.2.conv.0.conv.input_quantizer', 'mobvit_blocks.2.conv.0.conv.weight_quantizer', 'mobvit_blocks.2.conv.0.conv.output_quantizer', 'mobvit_blocks.2.conv.0.conv.output_quantizer', 'mobvit_blocks.2.conv.0.norm', 'mobvit_blocks.2.conv.1.conv.input_quantizer', 'mobvit_blocks.2.conv.1.conv.input_quantizer', 'mobvit_blocks.2.conv.1.conv.weight_quantizer', 'mobvit_blocks.2.conv.1.conv.output_quantizer', 'mobvit_blocks.2.conv.1.conv.output_quantizer', 'mobvit_blocks.2.conv.1.norm', 'mobvit_blocks.2.conv.2.conv.input_quantizer', 'mobvit_blocks.2.conv.2.conv.input_quantizer', 'mobvit_blocks.2.conv.2.conv.weight_quantizer', 'mobvit_blocks.2.conv.2.conv.output_quantizer', 'mobvit_blocks.2.conv.2.conv.output_quantizer', 'mobvit_blocks.2.conv.2.norm', 'mobvit_blocks.3.conv.0.conv.input_quantizer', 'mobvit_blocks.3.conv.0.conv.input_quantizer', 'mobvit_blocks.3.conv.0.conv.weight_quantizer', 'mobvit_blocks.3.conv.0.conv.output_quantizer', 'mobvit_blocks.3.conv.0.conv.output_quantizer', 'mobvit_blocks.3.conv.0.norm', 'mobvit_blocks.3.conv.1.conv.input_quantizer', 'mobvit_blocks.3.conv.1.conv.input_quantizer', 'mobvit_blocks.3.conv.1.conv.weight_quantizer', 'mobvit_blocks.3.conv.1.conv.output_quantizer', 'mobvit_blocks.3.conv.1.conv.output_quantizer', 'mobvit_blocks.3.conv.1.norm', 'mobvit_blocks.3.conv.2.conv.input_quantizer', 'mobvit_blocks.3.conv.2.conv.input_quantizer', 'mobvit_blocks.3.conv.2.conv.weight_quantizer', 'mobvit_blocks.3.conv.2.conv.output_quantizer', 'mobvit_blocks.3.conv.2.conv.output_quantizer', 'mobvit_blocks.3.conv.2.norm', 'mobvit_blocks.4.conv1.conv.input_quantizer', 'mobvit_blocks.4.conv1.conv.input_quantizer', 'mobvit_blocks.4.conv1.conv.weight_quantizer', 'mobvit_blocks.4.conv1.conv.output_quantizer', 'mobvit_blocks.4.conv1.conv.output_quantizer', 'mobvit_blocks.4.conv1.norm', 'mobvit_blocks.4.conv2.conv.input_quantizer', 'mobvit_blocks.4.conv2.conv.input_quantizer', 'mobvit_blocks.4.conv2.conv.weight_quantizer', 'mobvit_blocks.4.conv2.conv.output_quantizer', 'mobvit_blocks.4.conv2.conv.output_quantizer', 'mobvit_blocks.4.conv2.norm', 'mobvit_blocks.4.transformer_layers.0.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.0.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.1.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.2.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.3.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.4.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.5.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.6.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.0.experts.7.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.0.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.1.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.2.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.3.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.4.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.5.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.6.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear1.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear1.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear1.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear2.linear.input_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear2.linear.weight_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear2.linear.output_quantizer', 'mobvit_blocks.4.transformer_layers.1.experts.7.linear2.linear.output_quantizer', 'mobvit_blocks.4.conv3.conv.input_quantizer', 'mobvit_blocks.4.conv3.conv.input_quantizer', 'mobvit_blocks.4.conv3.conv.weight_quantizer', 'mobvit_blocks.4.conv3.conv.output_quantizer', 'mobvit_blocks.4.conv3.conv.output_quantizer', 'mobvit_blocks.4.conv3.norm', 'mobvit_blocks.4.conv4.conv.input_quantizer', 'mobvit_blocks.4.conv4.conv.input_quantizer', 'mobvit_blocks.4.conv4.conv.weight_quantizer', 'mobvit_blocks.4.conv4.conv.output_quantizer', 'mobvit_blocks.4.conv4.conv.output_quantizer', 'mobvit_blocks.4.conv4.norm', 'mobvit_blocks.5.conv.0.conv.input_quantizer', 'mobvit_blocks.5.conv.0.conv.input_quantizer', 'mobvit_blocks.5.conv.0.conv.weight_quantizer', 'mobvit_blocks.5.conv.0.conv.output_quantizer', 'mobvit_blocks.5.conv.0.conv.output_quantizer', 'mobvit_blocks.5.conv.0.norm', 'mobvit_blocks.5.conv.1.conv.input_quantizer', 'mobvit_blocks.5.conv.1.conv.input_quantizer', 'mobvit_blocks.5.conv.1.conv.weight_quantizer', 'mobvit_blocks.5.conv.1.conv.output_quantizer', 'mobvit_blocks.5.conv.1.conv.output_quantizer', 'mobvit_blocks.5.conv.1.norm', 'mobvit_blocks.5.conv.2.conv.input_quantizer', 'mobvit_blocks.5.conv.2.conv.input_quantizer', 'mobvit_blocks.5.conv.2.conv.weight_quantizer', 'mobvit_blocks.5.conv.2.conv.output_quantizer', 'mobvit_blocks.5.conv.2.conv.output_quantizer', 'mobvit_blocks.5.conv.2.norm', 'mobvit_blocks.6.conv1.conv.input_quantizer', 'mobvit_blocks.6.conv1.conv.input_quantizer', 'mobvit_blocks.6.conv1.conv.weight_quantizer', 'mobvit_blocks.6.conv1.conv.output_quantizer', 'mobvit_blocks.6.conv1.conv.output_quantizer', 'mobvit_blocks.6.conv1.norm', 'mobvit_blocks.6.conv2.conv.input_quantizer', 'mobvit_blocks.6.conv2.conv.input_quantizer', 'mobvit_blocks.6.conv2.conv.weight_quantizer', 'mobvit_blocks.6.conv2.conv.output_quantizer', 'mobvit_blocks.6.conv2.conv.output_quantizer', 'mobvit_blocks.6.conv2.norm', 'mobvit_blocks.6.transformer_layers.0.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear1.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear1.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear1.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear1.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear1.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear2.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear2.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear2.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear2.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.0.linear2.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear1.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear1.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear1.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear1.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear1.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear2.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear2.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear2.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear2.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.1.linear2.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear1.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear1.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear1.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear1.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear1.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear2.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear2.linear.input_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear2.linear.weight_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear2.linear.output_quantizer', 'mobvit_blocks.6.transformer_layers.2.linear2.linear.output_quantizer', 'mobvit_blocks.6.conv3.conv.input_quantizer', 'mobvit_blocks.6.conv3.conv.input_quantizer', 'mobvit_blocks.6.conv3.conv.weight_quantizer', 'mobvit_blocks.6.conv3.conv.output_quantizer', 'mobvit_blocks.6.conv3.conv.output_quantizer', 'mobvit_blocks.6.conv3.norm', 'mobvit_blocks.6.conv4.conv.input_quantizer', 'mobvit_blocks.6.conv4.conv.input_quantizer', 'mobvit_blocks.6.conv4.conv.weight_quantizer', 'mobvit_blocks.6.conv4.conv.output_quantizer', 'mobvit_blocks.6.conv4.conv.output_quantizer', 'mobvit_blocks.6.conv4.norm', 'mobvit_blocks.7.conv.0.conv.input_quantizer', 'mobvit_blocks.7.conv.0.conv.input_quantizer', 'mobvit_blocks.7.conv.0.conv.weight_quantizer', 'mobvit_blocks.7.conv.0.conv.output_quantizer', 'mobvit_blocks.7.conv.0.conv.output_quantizer', 'mobvit_blocks.7.conv.0.norm', 'mobvit_blocks.7.conv.1.conv.input_quantizer', 'mobvit_blocks.7.conv.1.conv.input_quantizer', 'mobvit_blocks.7.conv.1.conv.weight_quantizer', 'mobvit_blocks.7.conv.1.conv.output_quantizer', 'mobvit_blocks.7.conv.1.conv.output_quantizer', 'mobvit_blocks.7.conv.1.norm', 'mobvit_blocks.7.conv.2.conv.input_quantizer', 'mobvit_blocks.7.conv.2.conv.input_quantizer', 'mobvit_blocks.7.conv.2.conv.weight_quantizer', 'mobvit_blocks.7.conv.2.conv.output_quantizer', 'mobvit_blocks.7.conv.2.conv.output_quantizer', 'mobvit_blocks.7.conv.2.norm', 'mobvit_blocks.8.conv1.conv.input_quantizer', 'mobvit_blocks.8.conv1.conv.input_quantizer', 'mobvit_blocks.8.conv1.conv.weight_quantizer', 'mobvit_blocks.8.conv1.conv.output_quantizer', 'mobvit_blocks.8.conv1.conv.output_quantizer', 'mobvit_blocks.8.conv1.norm', 'mobvit_blocks.8.conv2.conv.input_quantizer', 'mobvit_blocks.8.conv2.conv.input_quantizer', 'mobvit_blocks.8.conv2.conv.weight_quantizer', 'mobvit_blocks.8.conv2.conv.output_quantizer', 'mobvit_blocks.8.conv2.conv.output_quantizer', 'mobvit_blocks.8.conv2.norm', 'mobvit_blocks.8.transformer_layers.0.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear1.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear1.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear1.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear1.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear1.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear2.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear2.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear2.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear2.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.0.linear2.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.qkv.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.qkv.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.qkv.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.proj.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.proj.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.proj.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.quantized_matmul.matmul.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.quantized_matmul.matmul.weight_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.self_attn.quantized_matmul.matmul.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear1.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear1.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear1.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear1.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear1.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear2.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear2.linear.input_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear2.linear.weight_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear2.linear.output_quantizer', 'mobvit_blocks.8.transformer_layers.1.linear2.linear.output_quantizer', 'mobvit_blocks.8.conv3.conv.input_quantizer', 'mobvit_blocks.8.conv3.conv.input_quantizer', 'mobvit_blocks.8.conv3.conv.weight_quantizer', 'mobvit_blocks.8.conv3.conv.output_quantizer', 'mobvit_blocks.8.conv3.conv.output_quantizer', 'mobvit_blocks.8.conv3.norm', 'mobvit_blocks.8.conv4.conv.input_quantizer', 'mobvit_blocks.8.conv4.conv.input_quantizer', 'mobvit_blocks.8.conv4.conv.weight_quantizer', 'mobvit_blocks.8.conv4.conv.output_quantizer', 'mobvit_blocks.8.conv4.conv.output_quantizer', 'mobvit_blocks.8.conv4.norm', 'conv_last.conv.input_quantizer', 'conv_last.conv.input_quantizer', 'conv_last.conv.weight_quantizer', 'conv_last.conv.output_quantizer', 'conv_last.conv.output_quantizer', 'conv_last.norm', 'final_layer.linear.input_quantizer', 'final_layer.linear.input_quantizer', 'final_layer.linear.weight_quantizer', 'final_layer.linear.output_quantizer', 'final_layer.linear.output_quantizer']/home/xinyuzh/workspace/DAC2025_Train_public/train.py:312: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  grad_scaler = amp.GradScaler(enabled=getattr(configs.run, "fp16", False))
[38;21m2024-11-12 21:37:29,859 - train.py[line:313] - INFO: Number of parameters: 677360[0m
[38;21m2024-11-12 21:37:29,859 - train.py[line:318] - INFO: Current checkpoint: ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt[0m
[38;21m2024-11-12 21:37:29,860 - train.py[line:354] - INFO: Experiment starts.[0m

{}
/home/xinyuzh/workspace/DAC2025_Train_public/train.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=grad_scaler._enabled):
[38;21m2024-11-12 21:37:30,630 - train.py[line:120] - INFO: Train Epoch: 1 [     64/  45000 (  0%)] Loss: 2.5499e+00 class Loss: 2.5499e+00[0m
[38;21m2024-11-12 21:38:28,530 - train.py[line:120] - INFO: Train Epoch: 1 [  12864/  45000 ( 29%)] Loss: 2.0248e+00 class Loss: 2.0248e+00[0m
[38;21m2024-11-12 21:39:25,558 - train.py[line:120] - INFO: Train Epoch: 1 [  25664/  45000 ( 57%)] Loss: 2.1019e+00 class Loss: 2.1019e+00[0m
[38;21m2024-11-12 21:40:22,176 - train.py[line:120] - INFO: Train Epoch: 1 [  38464/  45000 ( 85%)] Loss: 1.8229e+00 class Loss: 1.8229e+00[0m
[38;21m2024-11-12 21:40:50,836 - train.py[line:132] - INFO: Train class Loss: 1.9905e+00, Accuracy: 10844/45000 (24.10%)[0m
/home/xinyuzh/workspace/DAC2025_Train_public/train.py:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=fp16):
[38;21m2024-11-12 21:40:59,376 - train.py[line:178] - INFO: 
Validation set: Average loss: 1.7355e+00, Accuracy: 1549/5000 (30.98%)
[0m
/home/xinyuzh/workspace/DAC2025_Train_public/train.py:199: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=fp16):
[38;21m2024-11-12 21:41:16,271 - train.py[line:220] - INFO: 
Test set: Average loss: 1.7173e+00, Accuracy: 3233/10000 (32.33%)
[0m
[I] Model saved to ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1_acc-30.98_epoch-1.pt. Current best 3: [(30.98, 1)]
[38;21m2024-11-12 21:41:16,777 - train.py[line:120] - INFO: Train Epoch: 2 [     64/  45000 (  0%)] Loss: 1.7601e+00 class Loss: 1.7601e+00[0m
[38;21m2024-11-12 21:42:12,279 - train.py[line:120] - INFO: Train Epoch: 2 [  12864/  45000 ( 29%)] Loss: 1.7287e+00 class Loss: 1.7287e+00[0m
[38;21m2024-11-12 21:43:08,314 - train.py[line:120] - INFO: Train Epoch: 2 [  25664/  45000 ( 57%)] Loss: 1.8645e+00 class Loss: 1.8645e+00[0m
[38;21m2024-11-12 21:44:04,472 - train.py[line:120] - INFO: Train Epoch: 2 [  38464/  45000 ( 85%)] Loss: 1.6079e+00 class Loss: 1.6079e+00[0m
[38;21m2024-11-12 21:44:32,777 - train.py[line:132] - INFO: Train class Loss: 1.7138e+00, Accuracy: 15846/45000 (35.21%)[0m
[38;21m2024-11-12 21:44:41,190 - train.py[line:178] - INFO: 
Validation set: Average loss: 1.6149e+00, Accuracy: 2008/5000 (40.16%)
[0m
[38;21m2024-11-12 21:44:58,041 - train.py[line:220] - INFO: 
Test set: Average loss: 1.6092e+00, Accuracy: 4067/10000 (40.67%)
[0m
[I] Model saved to ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1_acc-40.16_epoch-2.pt. Current best 3: [(40.16, 2), (30.98, 1)]
[38;21m2024-11-12 21:44:58,612 - train.py[line:120] - INFO: Train Epoch: 3 [     64/  45000 (  0%)] Loss: 1.7442e+00 class Loss: 1.7442e+00[0m
[38;21m2024-11-12 21:45:59,184 - train.py[line:120] - INFO: Train Epoch: 3 [  12864/  45000 ( 29%)] Loss: 1.6442e+00 class Loss: 1.6442e+00[0m
[38;21m2024-11-12 21:47:01,669 - train.py[line:120] - INFO: Train Epoch: 3 [  25664/  45000 ( 57%)] Loss: 1.6273e+00 class Loss: 1.6273e+00[0m
[38;21m2024-11-12 21:48:04,984 - train.py[line:120] - INFO: Train Epoch: 3 [  38464/  45000 ( 85%)] Loss: 1.5643e+00 class Loss: 1.5643e+00[0m
[38;21m2024-11-12 21:48:37,005 - train.py[line:132] - INFO: Train class Loss: 1.5739e+00, Accuracy: 18651/45000 (41.45%)[0m
[38;21m2024-11-12 21:48:46,376 - train.py[line:178] - INFO: 
Validation set: Average loss: 1.4712e+00, Accuracy: 2223/5000 (44.46%)
[0m
[38;21m2024-11-12 21:49:04,306 - train.py[line:220] - INFO: 
Test set: Average loss: 1.4529e+00, Accuracy: 4618/10000 (46.18%)
[0m
[I] Model saved to ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1_acc-44.46_epoch-3.pt. Current best 3: [(44.46, 3), (40.16, 2), (30.98, 1)]
[38;21m2024-11-12 21:49:04,880 - train.py[line:120] - INFO: Train Epoch: 4 [     64/  45000 (  0%)] Loss: 1.6202e+00 class Loss: 1.6202e+00[0m
[38;21m2024-11-12 21:50:06,911 - train.py[line:120] - INFO: Train Epoch: 4 [  12864/  45000 ( 29%)] Loss: 1.4832e+00 class Loss: 1.4832e+00[0m
[38;21m2024-11-12 21:51:02,815 - train.py[line:120] - INFO: Train Epoch: 4 [  25664/  45000 ( 57%)] Loss: 2.3031e+00 class Loss: 2.3031e+00[0m
[38;21m2024-11-12 21:51:57,348 - train.py[line:120] - INFO: Train Epoch: 4 [  38464/  45000 ( 85%)] Loss: 2.3028e+00 class Loss: 2.3028e+00[0m
[38;21m2024-11-12 21:52:24,881 - train.py[line:132] - INFO: Train class Loss: 2.0074e+00, Accuracy: 10609/45000 (23.58%)[0m
[38;21m2024-11-12 21:52:33,132 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3190e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 21:52:49,675 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3197e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 21:52:50,228 - train.py[line:120] - INFO: Train Epoch: 5 [     64/  45000 (  0%)] Loss: 2.3029e+00 class Loss: 2.3029e+00[0m
[38;21m2024-11-12 21:53:46,607 - train.py[line:120] - INFO: Train Epoch: 5 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:54:41,482 - train.py[line:120] - INFO: Train Epoch: 5 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:55:38,726 - train.py[line:120] - INFO: Train Epoch: 5 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:56:07,157 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 21:56:15,826 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 21:56:32,446 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 21:56:33,177 - train.py[line:120] - INFO: Train Epoch: 6 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:57:27,716 - train.py[line:120] - INFO: Train Epoch: 6 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:58:21,834 - train.py[line:120] - INFO: Train Epoch: 6 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:59:15,377 - train.py[line:120] - INFO: Train Epoch: 6 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 21:59:43,056 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 21:59:51,368 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:00:07,871 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:00:08,379 - train.py[line:120] - INFO: Train Epoch: 7 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:01:02,267 - train.py[line:120] - INFO: Train Epoch: 7 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:01:56,259 - train.py[line:120] - INFO: Train Epoch: 7 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:02:50,687 - train.py[line:120] - INFO: Train Epoch: 7 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:03:21,331 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:03:30,341 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:03:48,146 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:03:48,670 - train.py[line:120] - INFO: Train Epoch: 8 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:04:50,348 - train.py[line:120] - INFO: Train Epoch: 8 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:05:51,185 - train.py[line:120] - INFO: Train Epoch: 8 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:06:52,873 - train.py[line:120] - INFO: Train Epoch: 8 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:07:23,892 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:07:32,316 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 22:07:48,888 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:07:49,429 - train.py[line:120] - INFO: Train Epoch: 9 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:08:45,395 - train.py[line:120] - INFO: Train Epoch: 9 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:09:39,629 - train.py[line:120] - INFO: Train Epoch: 9 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:10:33,907 - train.py[line:120] - INFO: Train Epoch: 9 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:11:01,715 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:11:10,258 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:11:26,949 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:11:27,426 - train.py[line:120] - INFO: Train Epoch: 10 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:12:22,736 - train.py[line:120] - INFO: Train Epoch: 10 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:13:17,488 - train.py[line:120] - INFO: Train Epoch: 10 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:14:12,668 - train.py[line:120] - INFO: Train Epoch: 10 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:14:40,984 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:14:49,572 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 22:15:06,187 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:15:06,644 - train.py[line:120] - INFO: Train Epoch: 11 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:16:02,129 - train.py[line:120] - INFO: Train Epoch: 11 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:17:00,411 - train.py[line:120] - INFO: Train Epoch: 11 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:18:01,095 - train.py[line:120] - INFO: Train Epoch: 11 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:18:32,566 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:18:41,869 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 22:18:59,430 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:18:59,971 - train.py[line:120] - INFO: Train Epoch: 12 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:19:59,918 - train.py[line:120] - INFO: Train Epoch: 12 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:20:55,579 - train.py[line:120] - INFO: Train Epoch: 12 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:21:50,912 - train.py[line:120] - INFO: Train Epoch: 12 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:22:20,331 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:22:28,782 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:22:45,323 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:22:45,777 - train.py[line:120] - INFO: Train Epoch: 13 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:23:41,373 - train.py[line:120] - INFO: Train Epoch: 13 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:24:37,174 - train.py[line:120] - INFO: Train Epoch: 13 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:25:31,458 - train.py[line:120] - INFO: Train Epoch: 13 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:26:00,118 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:26:08,821 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3209e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 22:26:25,387 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:26:25,819 - train.py[line:120] - INFO: Train Epoch: 14 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:27:22,304 - train.py[line:120] - INFO: Train Epoch: 14 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:28:16,100 - train.py[line:120] - INFO: Train Epoch: 14 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:29:15,069 - train.py[line:120] - INFO: Train Epoch: 14 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:29:47,280 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:29:56,412 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:30:14,098 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:30:14,632 - train.py[line:120] - INFO: Train Epoch: 15 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:31:15,780 - train.py[line:120] - INFO: Train Epoch: 15 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:32:17,281 - train.py[line:120] - INFO: Train Epoch: 15 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:33:17,087 - train.py[line:120] - INFO: Train Epoch: 15 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:33:45,554 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:33:54,096 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3179e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:34:10,744 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3196e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:34:11,184 - train.py[line:120] - INFO: Train Epoch: 16 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:35:07,258 - train.py[line:120] - INFO: Train Epoch: 16 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:36:03,219 - train.py[line:120] - INFO: Train Epoch: 16 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:36:57,881 - train.py[line:120] - INFO: Train Epoch: 16 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:37:26,040 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:37:34,733 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:37:52,834 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:37:53,322 - train.py[line:120] - INFO: Train Epoch: 17 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:38:54,801 - train.py[line:120] - INFO: Train Epoch: 17 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:39:57,356 - train.py[line:120] - INFO: Train Epoch: 17 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:41:00,488 - train.py[line:120] - INFO: Train Epoch: 17 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:41:32,821 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:41:41,450 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3190e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:41:58,181 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3197e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:41:58,674 - train.py[line:120] - INFO: Train Epoch: 18 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:42:53,814 - train.py[line:120] - INFO: Train Epoch: 18 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:43:48,782 - train.py[line:120] - INFO: Train Epoch: 18 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:44:44,086 - train.py[line:120] - INFO: Train Epoch: 18 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:45:12,715 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:45:21,274 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3126e+00, Accuracy: 471/5000 (9.42%)
[0m
[38;21m2024-11-12 22:45:37,779 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3103e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.42): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:45:38,205 - train.py[line:120] - INFO: Train Epoch: 19 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:46:36,307 - train.py[line:120] - INFO: Train Epoch: 19 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:47:39,214 - train.py[line:120] - INFO: Train Epoch: 19 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:48:41,268 - train.py[line:120] - INFO: Train Epoch: 19 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:49:13,280 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:49:22,437 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3083e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 22:49:40,417 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3059e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:49:40,964 - train.py[line:120] - INFO: Train Epoch: 20 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:50:38,629 - train.py[line:120] - INFO: Train Epoch: 20 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:51:33,778 - train.py[line:120] - INFO: Train Epoch: 20 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:52:29,156 - train.py[line:120] - INFO: Train Epoch: 20 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:52:58,033 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:53:06,449 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 22:53:23,022 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:53:23,501 - train.py[line:120] - INFO: Train Epoch: 21 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:54:18,747 - train.py[line:120] - INFO: Train Epoch: 21 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:55:19,755 - train.py[line:120] - INFO: Train Epoch: 21 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:56:21,506 - train.py[line:120] - INFO: Train Epoch: 21 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:56:53,053 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 22:57:01,909 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 22:57:20,158 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 22:57:20,662 - train.py[line:120] - INFO: Train Epoch: 22 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:58:26,229 - train.py[line:120] - INFO: Train Epoch: 22 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 22:59:23,867 - train.py[line:120] - INFO: Train Epoch: 22 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:00:22,360 - train.py[line:120] - INFO: Train Epoch: 22 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:00:52,919 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:01:01,386 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 23:01:18,055 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3164e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:01:18,542 - train.py[line:120] - INFO: Train Epoch: 23 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:02:16,976 - train.py[line:120] - INFO: Train Epoch: 23 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:03:18,574 - train.py[line:120] - INFO: Train Epoch: 23 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:04:24,454 - train.py[line:120] - INFO: Train Epoch: 23 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:04:57,998 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:05:07,435 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3223e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 23:05:25,430 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:05:25,988 - train.py[line:120] - INFO: Train Epoch: 24 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:06:27,271 - train.py[line:120] - INFO: Train Epoch: 24 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:07:26,455 - train.py[line:120] - INFO: Train Epoch: 24 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:08:22,143 - train.py[line:120] - INFO: Train Epoch: 24 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:08:50,656 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:08:59,211 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 23:09:15,661 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:09:16,125 - train.py[line:120] - INFO: Train Epoch: 25 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:10:12,029 - train.py[line:120] - INFO: Train Epoch: 25 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:11:07,662 - train.py[line:120] - INFO: Train Epoch: 25 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:12:07,939 - train.py[line:120] - INFO: Train Epoch: 25 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:12:39,253 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:12:48,436 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3147e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 23:13:06,587 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3165e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:13:07,189 - train.py[line:120] - INFO: Train Epoch: 26 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:14:09,413 - train.py[line:120] - INFO: Train Epoch: 26 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:15:11,885 - train.py[line:120] - INFO: Train Epoch: 26 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:16:09,595 - train.py[line:120] - INFO: Train Epoch: 26 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:16:39,218 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:16:47,750 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 23:17:04,490 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:17:04,974 - train.py[line:120] - INFO: Train Epoch: 27 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:18:01,050 - train.py[line:120] - INFO: Train Epoch: 27 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:18:56,580 - train.py[line:120] - INFO: Train Epoch: 27 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:19:53,463 - train.py[line:120] - INFO: Train Epoch: 27 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:20:25,270 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:20:34,502 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 23:20:52,205 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:20:52,817 - train.py[line:120] - INFO: Train Epoch: 28 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:21:56,724 - train.py[line:120] - INFO: Train Epoch: 28 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:22:59,886 - train.py[line:120] - INFO: Train Epoch: 28 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:23:58,350 - train.py[line:120] - INFO: Train Epoch: 28 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:24:26,909 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:24:35,278 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 23:24:51,703 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:24:52,187 - train.py[line:120] - INFO: Train Epoch: 29 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:25:46,531 - train.py[line:120] - INFO: Train Epoch: 29 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:26:41,277 - train.py[line:120] - INFO: Train Epoch: 29 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:27:35,992 - train.py[line:120] - INFO: Train Epoch: 29 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:28:05,933 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:28:14,952 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3151e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 23:28:32,973 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3191e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:28:33,533 - train.py[line:120] - INFO: Train Epoch: 30 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:29:36,074 - train.py[line:120] - INFO: Train Epoch: 30 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:30:37,859 - train.py[line:120] - INFO: Train Epoch: 30 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:31:39,079 - train.py[line:120] - INFO: Train Epoch: 30 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:32:09,951 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:32:18,182 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 23:32:34,797 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:32:35,259 - train.py[line:120] - INFO: Train Epoch: 31 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:33:30,692 - train.py[line:120] - INFO: Train Epoch: 31 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:34:25,690 - train.py[line:120] - INFO: Train Epoch: 31 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:35:21,428 - train.py[line:120] - INFO: Train Epoch: 31 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:35:49,303 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:35:57,588 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 23:36:14,540 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:36:15,122 - train.py[line:120] - INFO: Train Epoch: 32 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:37:21,221 - train.py[line:120] - INFO: Train Epoch: 32 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:38:25,471 - train.py[line:120] - INFO: Train Epoch: 32 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:39:28,012 - train.py[line:120] - INFO: Train Epoch: 32 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:40:00,197 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:40:09,236 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 23:40:26,947 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:40:27,450 - train.py[line:120] - INFO: Train Epoch: 33 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:41:25,164 - train.py[line:120] - INFO: Train Epoch: 33 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:42:21,087 - train.py[line:120] - INFO: Train Epoch: 33 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:43:16,843 - train.py[line:120] - INFO: Train Epoch: 33 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:43:45,430 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:43:53,852 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3167e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 23:44:10,297 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:44:10,782 - train.py[line:120] - INFO: Train Epoch: 34 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:45:05,979 - train.py[line:120] - INFO: Train Epoch: 34 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:46:07,989 - train.py[line:120] - INFO: Train Epoch: 34 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:47:09,400 - train.py[line:120] - INFO: Train Epoch: 34 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:47:41,003 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:47:50,111 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 23:48:07,888 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:48:08,438 - train.py[line:120] - INFO: Train Epoch: 35 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:49:13,315 - train.py[line:120] - INFO: Train Epoch: 35 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:50:09,617 - train.py[line:120] - INFO: Train Epoch: 35 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:51:04,442 - train.py[line:120] - INFO: Train Epoch: 35 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:51:33,280 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:51:41,716 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3191e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-12 23:51:58,063 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3198e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:51:58,485 - train.py[line:120] - INFO: Train Epoch: 36 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:52:53,901 - train.py[line:120] - INFO: Train Epoch: 36 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:53:49,150 - train.py[line:120] - INFO: Train Epoch: 36 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:54:44,095 - train.py[line:120] - INFO: Train Epoch: 36 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:55:12,433 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:55:20,979 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3168e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-12 23:55:37,427 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:55:37,882 - train.py[line:120] - INFO: Train Epoch: 37 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:56:33,848 - train.py[line:120] - INFO: Train Epoch: 37 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:57:29,670 - train.py[line:120] - INFO: Train Epoch: 37 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:58:24,794 - train.py[line:120] - INFO: Train Epoch: 37 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-12 23:58:53,443 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-12 23:59:02,006 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-12 23:59:18,570 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-12 23:59:19,023 - train.py[line:120] - INFO: Train Epoch: 38 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:00:14,651 - train.py[line:120] - INFO: Train Epoch: 38 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:01:08,814 - train.py[line:120] - INFO: Train Epoch: 38 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:02:05,441 - train.py[line:120] - INFO: Train Epoch: 38 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:02:34,520 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:02:43,269 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 00:03:00,033 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:03:00,431 - train.py[line:120] - INFO: Train Epoch: 39 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:03:55,188 - train.py[line:120] - INFO: Train Epoch: 39 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:04:51,521 - train.py[line:120] - INFO: Train Epoch: 39 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:05:48,055 - train.py[line:120] - INFO: Train Epoch: 39 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:06:17,357 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:06:25,786 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3130e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:06:42,353 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3114e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:06:42,912 - train.py[line:120] - INFO: Train Epoch: 40 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:07:39,311 - train.py[line:120] - INFO: Train Epoch: 40 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:08:34,954 - train.py[line:120] - INFO: Train Epoch: 40 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:09:32,667 - train.py[line:120] - INFO: Train Epoch: 40 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:10:01,590 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:10:10,155 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:10:27,062 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:10:27,570 - train.py[line:120] - INFO: Train Epoch: 41 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:11:23,288 - train.py[line:120] - INFO: Train Epoch: 41 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:12:19,952 - train.py[line:120] - INFO: Train Epoch: 41 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:13:16,781 - train.py[line:120] - INFO: Train Epoch: 41 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:13:45,597 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:13:54,051 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3139e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:14:10,644 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3164e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:14:11,102 - train.py[line:120] - INFO: Train Epoch: 42 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:15:06,518 - train.py[line:120] - INFO: Train Epoch: 42 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:16:03,383 - train.py[line:120] - INFO: Train Epoch: 42 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:16:58,689 - train.py[line:120] - INFO: Train Epoch: 42 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:17:27,953 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:17:36,586 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 00:17:53,119 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:17:53,553 - train.py[line:120] - INFO: Train Epoch: 43 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:18:49,316 - train.py[line:120] - INFO: Train Epoch: 43 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:19:44,095 - train.py[line:120] - INFO: Train Epoch: 43 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:20:43,527 - train.py[line:120] - INFO: Train Epoch: 43 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:21:13,964 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:21:22,380 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3212e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:21:38,972 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:21:39,478 - train.py[line:120] - INFO: Train Epoch: 44 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:22:39,853 - train.py[line:120] - INFO: Train Epoch: 44 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:23:35,546 - train.py[line:120] - INFO: Train Epoch: 44 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:24:32,184 - train.py[line:120] - INFO: Train Epoch: 44 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:25:00,507 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:25:09,017 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 00:25:26,015 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:25:26,553 - train.py[line:120] - INFO: Train Epoch: 45 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:26:23,117 - train.py[line:120] - INFO: Train Epoch: 45 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:27:19,248 - train.py[line:120] - INFO: Train Epoch: 45 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:28:14,526 - train.py[line:120] - INFO: Train Epoch: 45 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:28:43,662 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:28:52,134 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3212e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:29:08,754 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:29:09,259 - train.py[line:120] - INFO: Train Epoch: 46 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:30:05,266 - train.py[line:120] - INFO: Train Epoch: 46 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:31:01,566 - train.py[line:120] - INFO: Train Epoch: 46 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:31:57,632 - train.py[line:120] - INFO: Train Epoch: 46 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:32:26,072 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:32:34,678 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3187e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:32:51,372 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:32:51,893 - train.py[line:120] - INFO: Train Epoch: 47 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:33:47,183 - train.py[line:120] - INFO: Train Epoch: 47 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:34:43,246 - train.py[line:120] - INFO: Train Epoch: 47 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:35:38,973 - train.py[line:120] - INFO: Train Epoch: 47 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:36:07,670 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:36:16,174 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3190e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 00:36:32,820 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3197e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:36:33,322 - train.py[line:120] - INFO: Train Epoch: 48 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:37:28,985 - train.py[line:120] - INFO: Train Epoch: 48 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:38:24,954 - train.py[line:120] - INFO: Train Epoch: 48 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:39:21,006 - train.py[line:120] - INFO: Train Epoch: 48 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:39:49,826 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:39:58,321 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 00:40:15,191 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:40:15,679 - train.py[line:120] - INFO: Train Epoch: 49 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:41:11,864 - train.py[line:120] - INFO: Train Epoch: 49 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:42:07,709 - train.py[line:120] - INFO: Train Epoch: 49 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:43:03,490 - train.py[line:120] - INFO: Train Epoch: 49 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:43:32,636 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:43:41,115 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3196e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 00:43:57,730 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3221e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:43:58,236 - train.py[line:120] - INFO: Train Epoch: 50 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:44:53,224 - train.py[line:120] - INFO: Train Epoch: 50 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:45:48,364 - train.py[line:120] - INFO: Train Epoch: 50 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:46:44,509 - train.py[line:120] - INFO: Train Epoch: 50 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:47:13,687 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:47:22,113 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3168e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 00:47:38,810 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:47:39,278 - train.py[line:120] - INFO: Train Epoch: 51 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:48:37,189 - train.py[line:120] - INFO: Train Epoch: 51 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:49:32,995 - train.py[line:120] - INFO: Train Epoch: 51 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:50:29,086 - train.py[line:120] - INFO: Train Epoch: 51 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:50:57,680 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:51:06,221 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 00:51:23,070 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:51:23,500 - train.py[line:120] - INFO: Train Epoch: 52 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:52:19,890 - train.py[line:120] - INFO: Train Epoch: 52 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:53:16,957 - train.py[line:120] - INFO: Train Epoch: 52 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:54:14,308 - train.py[line:120] - INFO: Train Epoch: 52 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:54:43,070 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:54:51,584 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 00:55:08,350 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:55:08,868 - train.py[line:120] - INFO: Train Epoch: 53 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:56:04,345 - train.py[line:120] - INFO: Train Epoch: 53 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:56:58,274 - train.py[line:120] - INFO: Train Epoch: 53 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:57:53,698 - train.py[line:120] - INFO: Train Epoch: 53 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:58:22,160 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 00:58:30,750 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 00:58:47,382 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 00:58:47,893 - train.py[line:120] - INFO: Train Epoch: 54 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 00:59:44,964 - train.py[line:120] - INFO: Train Epoch: 54 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:00:40,317 - train.py[line:120] - INFO: Train Epoch: 54 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:01:36,078 - train.py[line:120] - INFO: Train Epoch: 54 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:02:05,143 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:02:13,755 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3169e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 01:02:30,519 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3162e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:02:31,020 - train.py[line:120] - INFO: Train Epoch: 55 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:03:26,315 - train.py[line:120] - INFO: Train Epoch: 55 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:04:21,207 - train.py[line:120] - INFO: Train Epoch: 55 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:05:16,264 - train.py[line:120] - INFO: Train Epoch: 55 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:05:45,116 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:05:53,613 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 01:06:10,084 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:06:10,549 - train.py[line:120] - INFO: Train Epoch: 56 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:07:06,104 - train.py[line:120] - INFO: Train Epoch: 56 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:08:01,722 - train.py[line:120] - INFO: Train Epoch: 56 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:08:56,714 - train.py[line:120] - INFO: Train Epoch: 56 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:09:25,018 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:09:33,518 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 01:09:50,104 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:09:50,579 - train.py[line:120] - INFO: Train Epoch: 57 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:10:45,766 - train.py[line:120] - INFO: Train Epoch: 57 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:11:40,884 - train.py[line:120] - INFO: Train Epoch: 57 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:12:36,159 - train.py[line:120] - INFO: Train Epoch: 57 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:13:04,834 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:13:13,507 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 01:13:30,073 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:13:30,565 - train.py[line:120] - INFO: Train Epoch: 58 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:14:26,441 - train.py[line:120] - INFO: Train Epoch: 58 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:15:21,367 - train.py[line:120] - INFO: Train Epoch: 58 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:16:16,265 - train.py[line:120] - INFO: Train Epoch: 58 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:16:44,705 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:16:53,275 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3126e+00, Accuracy: 471/5000 (9.42%)
[0m
[38;21m2024-11-13 01:17:09,878 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3103e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.42): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:17:10,287 - train.py[line:120] - INFO: Train Epoch: 59 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:18:07,932 - train.py[line:120] - INFO: Train Epoch: 59 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:19:04,068 - train.py[line:120] - INFO: Train Epoch: 59 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:20:00,209 - train.py[line:120] - INFO: Train Epoch: 59 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:20:28,623 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:20:37,229 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3126e+00, Accuracy: 471/5000 (9.42%)
[0m
[38;21m2024-11-13 01:20:53,838 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3103e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.42): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:20:54,376 - train.py[line:120] - INFO: Train Epoch: 60 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:21:49,921 - train.py[line:120] - INFO: Train Epoch: 60 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:22:45,679 - train.py[line:120] - INFO: Train Epoch: 60 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:23:43,198 - train.py[line:120] - INFO: Train Epoch: 60 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:24:12,268 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:24:20,800 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 01:24:37,636 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:24:38,144 - train.py[line:120] - INFO: Train Epoch: 61 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:25:32,947 - train.py[line:120] - INFO: Train Epoch: 61 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:26:29,329 - train.py[line:120] - INFO: Train Epoch: 61 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:27:24,630 - train.py[line:120] - INFO: Train Epoch: 61 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:27:52,865 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:28:01,424 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3151e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 01:28:18,322 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3191e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:28:18,795 - train.py[line:120] - INFO: Train Epoch: 62 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:29:13,894 - train.py[line:120] - INFO: Train Epoch: 62 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:30:09,873 - train.py[line:120] - INFO: Train Epoch: 62 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:31:05,258 - train.py[line:120] - INFO: Train Epoch: 62 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:31:33,683 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:31:42,373 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 01:31:59,293 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:31:59,771 - train.py[line:120] - INFO: Train Epoch: 63 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:32:55,630 - train.py[line:120] - INFO: Train Epoch: 63 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:33:50,854 - train.py[line:120] - INFO: Train Epoch: 63 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:34:46,398 - train.py[line:120] - INFO: Train Epoch: 63 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:35:15,720 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:35:24,250 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 01:35:41,067 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:35:41,601 - train.py[line:120] - INFO: Train Epoch: 64 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:36:37,015 - train.py[line:120] - INFO: Train Epoch: 64 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:37:32,278 - train.py[line:120] - INFO: Train Epoch: 64 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:38:27,203 - train.py[line:120] - INFO: Train Epoch: 64 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:38:55,823 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:39:04,397 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 01:39:21,223 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:39:21,776 - train.py[line:120] - INFO: Train Epoch: 65 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:40:17,300 - train.py[line:120] - INFO: Train Epoch: 65 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:41:12,535 - train.py[line:120] - INFO: Train Epoch: 65 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:42:07,779 - train.py[line:120] - INFO: Train Epoch: 65 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:42:35,504 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:42:43,980 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 01:43:00,822 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:43:01,295 - train.py[line:120] - INFO: Train Epoch: 66 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:43:56,494 - train.py[line:120] - INFO: Train Epoch: 66 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:44:50,217 - train.py[line:120] - INFO: Train Epoch: 66 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:45:44,727 - train.py[line:120] - INFO: Train Epoch: 66 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:46:12,566 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:46:20,991 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 01:46:37,460 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:46:37,910 - train.py[line:120] - INFO: Train Epoch: 67 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:47:32,085 - train.py[line:120] - INFO: Train Epoch: 67 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:48:27,270 - train.py[line:120] - INFO: Train Epoch: 67 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:49:21,192 - train.py[line:120] - INFO: Train Epoch: 67 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:49:48,806 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:49:57,075 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3147e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 01:50:13,524 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3165e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:50:14,051 - train.py[line:120] - INFO: Train Epoch: 68 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:51:08,714 - train.py[line:120] - INFO: Train Epoch: 68 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:52:04,017 - train.py[line:120] - INFO: Train Epoch: 68 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:52:57,847 - train.py[line:120] - INFO: Train Epoch: 68 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:53:25,546 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:53:33,857 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3160e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 01:53:50,117 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3164e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:53:50,570 - train.py[line:120] - INFO: Train Epoch: 69 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:54:44,222 - train.py[line:120] - INFO: Train Epoch: 69 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:55:38,912 - train.py[line:120] - INFO: Train Epoch: 69 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:56:34,253 - train.py[line:120] - INFO: Train Epoch: 69 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:57:02,322 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 01:57:10,813 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3119e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 01:57:27,628 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3116e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 01:57:28,122 - train.py[line:120] - INFO: Train Epoch: 70 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:58:22,699 - train.py[line:120] - INFO: Train Epoch: 70 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 01:59:17,093 - train.py[line:120] - INFO: Train Epoch: 70 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:00:11,166 - train.py[line:120] - INFO: Train Epoch: 70 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:00:39,507 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:00:48,003 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3151e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 02:01:04,423 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3191e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:01:04,886 - train.py[line:120] - INFO: Train Epoch: 71 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:02:00,917 - train.py[line:120] - INFO: Train Epoch: 71 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:02:55,498 - train.py[line:120] - INFO: Train Epoch: 71 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:03:50,797 - train.py[line:120] - INFO: Train Epoch: 71 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:04:18,752 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:04:27,238 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 02:04:44,009 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:04:44,477 - train.py[line:120] - INFO: Train Epoch: 72 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:05:38,560 - train.py[line:120] - INFO: Train Epoch: 72 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:06:33,494 - train.py[line:120] - INFO: Train Epoch: 72 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:07:28,361 - train.py[line:120] - INFO: Train Epoch: 72 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:07:56,790 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:08:05,301 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3128e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:08:21,899 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3158e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:08:22,349 - train.py[line:120] - INFO: Train Epoch: 73 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:09:17,608 - train.py[line:120] - INFO: Train Epoch: 73 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:10:12,222 - train.py[line:120] - INFO: Train Epoch: 73 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:11:07,537 - train.py[line:120] - INFO: Train Epoch: 73 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:11:36,600 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:11:45,160 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3140e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:12:02,163 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3159e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:12:02,618 - train.py[line:120] - INFO: Train Epoch: 74 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:12:57,832 - train.py[line:120] - INFO: Train Epoch: 74 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:13:52,670 - train.py[line:120] - INFO: Train Epoch: 74 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:14:47,099 - train.py[line:120] - INFO: Train Epoch: 74 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:15:15,465 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:15:23,831 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3168e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 02:15:40,241 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:15:40,839 - train.py[line:120] - INFO: Train Epoch: 75 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:16:36,719 - train.py[line:120] - INFO: Train Epoch: 75 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:17:31,449 - train.py[line:120] - INFO: Train Epoch: 75 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:18:26,314 - train.py[line:120] - INFO: Train Epoch: 75 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:18:54,165 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:19:02,745 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3187e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:19:19,330 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3194e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:19:19,774 - train.py[line:120] - INFO: Train Epoch: 76 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:20:15,182 - train.py[line:120] - INFO: Train Epoch: 76 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:21:10,549 - train.py[line:120] - INFO: Train Epoch: 76 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:22:05,532 - train.py[line:120] - INFO: Train Epoch: 76 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:22:34,318 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:22:42,785 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:22:59,509 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:23:00,016 - train.py[line:120] - INFO: Train Epoch: 77 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:23:54,627 - train.py[line:120] - INFO: Train Epoch: 77 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:24:49,793 - train.py[line:120] - INFO: Train Epoch: 77 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:25:44,820 - train.py[line:120] - INFO: Train Epoch: 77 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:26:13,362 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:26:21,862 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 02:26:38,581 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:26:39,096 - train.py[line:120] - INFO: Train Epoch: 78 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:27:34,012 - train.py[line:120] - INFO: Train Epoch: 78 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:28:29,448 - train.py[line:120] - INFO: Train Epoch: 78 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:29:25,366 - train.py[line:120] - INFO: Train Epoch: 78 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:29:53,311 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:30:01,734 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 02:30:18,242 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:30:18,699 - train.py[line:120] - INFO: Train Epoch: 79 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:31:13,272 - train.py[line:120] - INFO: Train Epoch: 79 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:32:07,748 - train.py[line:120] - INFO: Train Epoch: 79 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:33:02,355 - train.py[line:120] - INFO: Train Epoch: 79 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:33:30,875 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:33:39,269 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:33:55,918 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:33:56,484 - train.py[line:120] - INFO: Train Epoch: 80 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:34:51,252 - train.py[line:120] - INFO: Train Epoch: 80 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:35:49,007 - train.py[line:120] - INFO: Train Epoch: 80 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:36:46,207 - train.py[line:120] - INFO: Train Epoch: 80 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:37:16,151 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:37:24,763 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:37:41,135 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:37:41,614 - train.py[line:120] - INFO: Train Epoch: 81 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:38:41,652 - train.py[line:120] - INFO: Train Epoch: 81 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:39:41,800 - train.py[line:120] - INFO: Train Epoch: 81 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:40:40,475 - train.py[line:120] - INFO: Train Epoch: 81 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:41:11,565 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:41:20,105 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3168e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 02:41:36,422 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:41:36,891 - train.py[line:120] - INFO: Train Epoch: 82 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:42:36,906 - train.py[line:120] - INFO: Train Epoch: 82 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:43:35,266 - train.py[line:120] - INFO: Train Epoch: 82 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:44:33,226 - train.py[line:120] - INFO: Train Epoch: 82 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:45:02,788 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:45:12,062 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:45:28,660 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:45:29,174 - train.py[line:120] - INFO: Train Epoch: 83 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:46:24,925 - train.py[line:120] - INFO: Train Epoch: 83 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:47:21,755 - train.py[line:120] - INFO: Train Epoch: 83 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:48:18,115 - train.py[line:120] - INFO: Train Epoch: 83 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:48:46,728 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:48:55,393 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:49:12,289 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:49:12,794 - train.py[line:120] - INFO: Train Epoch: 84 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:50:08,693 - train.py[line:120] - INFO: Train Epoch: 84 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:51:05,742 - train.py[line:120] - INFO: Train Epoch: 84 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:52:02,236 - train.py[line:120] - INFO: Train Epoch: 84 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:52:32,055 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:52:40,699 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 02:52:57,625 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:52:58,174 - train.py[line:120] - INFO: Train Epoch: 85 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:53:55,776 - train.py[line:120] - INFO: Train Epoch: 85 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:54:52,793 - train.py[line:120] - INFO: Train Epoch: 85 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:55:47,980 - train.py[line:120] - INFO: Train Epoch: 85 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:56:17,119 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 02:56:25,880 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 02:56:42,854 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 02:56:43,395 - train.py[line:120] - INFO: Train Epoch: 86 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:57:39,714 - train.py[line:120] - INFO: Train Epoch: 86 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:58:37,697 - train.py[line:120] - INFO: Train Epoch: 86 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 02:59:33,955 - train.py[line:120] - INFO: Train Epoch: 86 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:00:03,797 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:00:12,416 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3234e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:00:29,398 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3215e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:00:29,927 - train.py[line:120] - INFO: Train Epoch: 87 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:01:27,545 - train.py[line:120] - INFO: Train Epoch: 87 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:02:23,609 - train.py[line:120] - INFO: Train Epoch: 87 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:03:21,694 - train.py[line:120] - INFO: Train Epoch: 87 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:03:50,603 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:03:59,669 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:04:16,654 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:04:17,166 - train.py[line:120] - INFO: Train Epoch: 88 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:05:14,309 - train.py[line:120] - INFO: Train Epoch: 88 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:06:10,203 - train.py[line:120] - INFO: Train Epoch: 88 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:07:07,220 - train.py[line:120] - INFO: Train Epoch: 88 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:07:36,794 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:07:45,476 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:08:02,421 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:08:02,960 - train.py[line:120] - INFO: Train Epoch: 89 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:09:01,316 - train.py[line:120] - INFO: Train Epoch: 89 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:09:57,496 - train.py[line:120] - INFO: Train Epoch: 89 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:10:56,576 - train.py[line:120] - INFO: Train Epoch: 89 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:11:27,150 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:11:35,797 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 03:11:52,635 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:11:53,160 - train.py[line:120] - INFO: Train Epoch: 90 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:12:53,703 - train.py[line:120] - INFO: Train Epoch: 90 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:13:54,861 - train.py[line:120] - INFO: Train Epoch: 90 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:14:55,801 - train.py[line:120] - INFO: Train Epoch: 90 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:15:27,423 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:15:36,502 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:15:53,553 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:15:54,141 - train.py[line:120] - INFO: Train Epoch: 91 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:16:54,576 - train.py[line:120] - INFO: Train Epoch: 91 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:17:54,817 - train.py[line:120] - INFO: Train Epoch: 91 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:18:55,226 - train.py[line:120] - INFO: Train Epoch: 91 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:19:25,520 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:19:34,295 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:19:51,612 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:19:52,129 - train.py[line:120] - INFO: Train Epoch: 92 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:20:48,277 - train.py[line:120] - INFO: Train Epoch: 92 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:21:47,264 - train.py[line:120] - INFO: Train Epoch: 92 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:22:45,405 - train.py[line:120] - INFO: Train Epoch: 92 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:23:14,964 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:23:23,510 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3026e+00, Accuracy: 499/5000 (9.98%)
[0m
[38;21m2024-11-13 03:23:40,406 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3026e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.98): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:23:40,903 - train.py[line:120] - INFO: Train Epoch: 93 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:24:37,180 - train.py[line:120] - INFO: Train Epoch: 93 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:25:33,417 - train.py[line:120] - INFO: Train Epoch: 93 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:26:29,706 - train.py[line:120] - INFO: Train Epoch: 93 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:26:58,756 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:27:07,347 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 03:27:24,343 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:27:24,843 - train.py[line:120] - INFO: Train Epoch: 94 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:28:22,641 - train.py[line:120] - INFO: Train Epoch: 94 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:29:19,962 - train.py[line:120] - INFO: Train Epoch: 94 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:30:16,096 - train.py[line:120] - INFO: Train Epoch: 94 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:30:44,926 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:30:53,814 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:31:10,662 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:31:11,188 - train.py[line:120] - INFO: Train Epoch: 95 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:32:07,252 - train.py[line:120] - INFO: Train Epoch: 95 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:33:01,917 - train.py[line:120] - INFO: Train Epoch: 95 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:33:57,400 - train.py[line:120] - INFO: Train Epoch: 95 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:34:26,006 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:34:34,590 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3190e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:34:51,103 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3197e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:34:51,636 - train.py[line:120] - INFO: Train Epoch: 96 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:35:49,146 - train.py[line:120] - INFO: Train Epoch: 96 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:36:44,509 - train.py[line:120] - INFO: Train Epoch: 96 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:37:40,643 - train.py[line:120] - INFO: Train Epoch: 96 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:38:10,438 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:38:19,163 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 03:38:36,052 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:38:36,534 - train.py[line:120] - INFO: Train Epoch: 97 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:39:33,175 - train.py[line:120] - INFO: Train Epoch: 97 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:40:29,172 - train.py[line:120] - INFO: Train Epoch: 97 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:41:25,758 - train.py[line:120] - INFO: Train Epoch: 97 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:41:54,477 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:42:03,175 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 03:42:19,926 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:42:20,503 - train.py[line:120] - INFO: Train Epoch: 98 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:43:17,597 - train.py[line:120] - INFO: Train Epoch: 98 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:44:15,171 - train.py[line:120] - INFO: Train Epoch: 98 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:45:09,808 - train.py[line:120] - INFO: Train Epoch: 98 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:45:38,778 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:45:47,535 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 03:46:04,413 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3202e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:46:04,914 - train.py[line:120] - INFO: Train Epoch: 99 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:47:01,212 - train.py[line:120] - INFO: Train Epoch: 99 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:47:57,433 - train.py[line:120] - INFO: Train Epoch: 99 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:48:53,022 - train.py[line:120] - INFO: Train Epoch: 99 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:49:23,738 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:49:32,571 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 03:49:49,109 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:49:49,571 - train.py[line:120] - INFO: Train Epoch: 100 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:50:48,962 - train.py[line:120] - INFO: Train Epoch: 100 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:51:49,294 - train.py[line:120] - INFO: Train Epoch: 100 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:52:48,636 - train.py[line:120] - INFO: Train Epoch: 100 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:53:19,076 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:53:27,721 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 03:53:44,293 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:53:44,786 - train.py[line:120] - INFO: Train Epoch: 101 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:54:45,295 - train.py[line:120] - INFO: Train Epoch: 101 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:55:45,853 - train.py[line:120] - INFO: Train Epoch: 101 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:56:45,906 - train.py[line:120] - INFO: Train Epoch: 101 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:57:16,868 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 03:57:25,249 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3223e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 03:57:41,567 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 03:57:42,047 - train.py[line:120] - INFO: Train Epoch: 102 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:58:40,998 - train.py[line:120] - INFO: Train Epoch: 102 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 03:59:39,692 - train.py[line:120] - INFO: Train Epoch: 102 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:00:39,312 - train.py[line:120] - INFO: Train Epoch: 102 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:01:10,516 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:01:19,240 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 04:01:35,845 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:01:36,347 - train.py[line:120] - INFO: Train Epoch: 103 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:02:36,282 - train.py[line:120] - INFO: Train Epoch: 103 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:03:35,438 - train.py[line:120] - INFO: Train Epoch: 103 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:04:35,277 - train.py[line:120] - INFO: Train Epoch: 103 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:05:06,207 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:05:14,680 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 04:05:31,287 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:05:31,759 - train.py[line:120] - INFO: Train Epoch: 104 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:06:31,820 - train.py[line:120] - INFO: Train Epoch: 104 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:07:31,640 - train.py[line:120] - INFO: Train Epoch: 104 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:08:30,431 - train.py[line:120] - INFO: Train Epoch: 104 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:09:00,422 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:09:08,897 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3223e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 04:09:25,513 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:09:26,004 - train.py[line:120] - INFO: Train Epoch: 105 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:10:25,393 - train.py[line:120] - INFO: Train Epoch: 105 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:11:24,846 - train.py[line:120] - INFO: Train Epoch: 105 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:12:23,750 - train.py[line:120] - INFO: Train Epoch: 105 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:12:54,302 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:13:02,768 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 04:13:19,229 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:13:19,712 - train.py[line:120] - INFO: Train Epoch: 106 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:14:18,880 - train.py[line:120] - INFO: Train Epoch: 106 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:15:17,720 - train.py[line:120] - INFO: Train Epoch: 106 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:16:16,165 - train.py[line:120] - INFO: Train Epoch: 106 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:16:46,483 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:16:54,873 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 04:17:11,287 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:17:11,799 - train.py[line:120] - INFO: Train Epoch: 107 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:18:10,669 - train.py[line:120] - INFO: Train Epoch: 107 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:19:09,889 - train.py[line:120] - INFO: Train Epoch: 107 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:20:09,379 - train.py[line:120] - INFO: Train Epoch: 107 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:20:41,098 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:20:49,688 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 04:21:06,521 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:21:07,051 - train.py[line:120] - INFO: Train Epoch: 108 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:22:06,469 - train.py[line:120] - INFO: Train Epoch: 108 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:23:06,778 - train.py[line:120] - INFO: Train Epoch: 108 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:24:07,123 - train.py[line:120] - INFO: Train Epoch: 108 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:24:35,891 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:24:44,478 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 04:25:01,186 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:25:01,710 - train.py[line:120] - INFO: Train Epoch: 109 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:25:57,471 - train.py[line:120] - INFO: Train Epoch: 109 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:26:54,274 - train.py[line:120] - INFO: Train Epoch: 109 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:27:50,921 - train.py[line:120] - INFO: Train Epoch: 109 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:28:20,006 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:28:28,553 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3173e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 04:28:45,252 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3162e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:28:45,688 - train.py[line:120] - INFO: Train Epoch: 110 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:29:39,734 - train.py[line:120] - INFO: Train Epoch: 110 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:30:35,195 - train.py[line:120] - INFO: Train Epoch: 110 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:31:29,242 - train.py[line:120] - INFO: Train Epoch: 110 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:31:57,150 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:32:05,582 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 04:32:22,087 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3202e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:32:22,617 - train.py[line:120] - INFO: Train Epoch: 111 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:33:16,492 - train.py[line:120] - INFO: Train Epoch: 111 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:34:09,870 - train.py[line:120] - INFO: Train Epoch: 111 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:35:03,665 - train.py[line:120] - INFO: Train Epoch: 111 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:35:32,097 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:35:40,791 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3169e+00, Accuracy: 499/5000 (9.98%)
[0m
[38;21m2024-11-13 04:35:57,829 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3181e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.98): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:35:58,310 - train.py[line:120] - INFO: Train Epoch: 112 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:36:51,671 - train.py[line:120] - INFO: Train Epoch: 112 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:37:44,811 - train.py[line:120] - INFO: Train Epoch: 112 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:38:39,151 - train.py[line:120] - INFO: Train Epoch: 112 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:39:07,176 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:39:15,863 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3151e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 04:39:32,545 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3178e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:39:33,062 - train.py[line:120] - INFO: Train Epoch: 113 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:40:26,805 - train.py[line:120] - INFO: Train Epoch: 113 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:41:21,410 - train.py[line:120] - INFO: Train Epoch: 113 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:42:15,914 - train.py[line:120] - INFO: Train Epoch: 113 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:42:44,641 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:42:53,103 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 04:43:09,873 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:43:10,343 - train.py[line:120] - INFO: Train Epoch: 114 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:44:04,220 - train.py[line:120] - INFO: Train Epoch: 114 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:45:00,583 - train.py[line:120] - INFO: Train Epoch: 114 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:45:54,817 - train.py[line:120] - INFO: Train Epoch: 114 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:46:23,053 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:46:31,639 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 04:46:48,378 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:46:48,928 - train.py[line:120] - INFO: Train Epoch: 115 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:47:43,398 - train.py[line:120] - INFO: Train Epoch: 115 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:48:37,132 - train.py[line:120] - INFO: Train Epoch: 115 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:49:30,720 - train.py[line:120] - INFO: Train Epoch: 115 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:49:59,043 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:50:07,714 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 04:50:24,505 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:50:25,053 - train.py[line:120] - INFO: Train Epoch: 116 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:51:19,993 - train.py[line:120] - INFO: Train Epoch: 116 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:52:15,234 - train.py[line:120] - INFO: Train Epoch: 116 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:53:09,405 - train.py[line:120] - INFO: Train Epoch: 116 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:53:37,220 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:53:45,901 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3130e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 04:54:03,208 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3114e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:54:03,738 - train.py[line:120] - INFO: Train Epoch: 117 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:54:56,560 - train.py[line:120] - INFO: Train Epoch: 117 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:55:50,112 - train.py[line:120] - INFO: Train Epoch: 117 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:56:44,344 - train.py[line:120] - INFO: Train Epoch: 117 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:57:12,125 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 04:57:20,708 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3126e+00, Accuracy: 471/5000 (9.42%)
[0m
[38;21m2024-11-13 04:57:37,518 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3103e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.42): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 04:57:38,073 - train.py[line:120] - INFO: Train Epoch: 118 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:58:31,528 - train.py[line:120] - INFO: Train Epoch: 118 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 04:59:25,475 - train.py[line:120] - INFO: Train Epoch: 118 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:00:19,113 - train.py[line:120] - INFO: Train Epoch: 118 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:00:47,024 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:00:55,908 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 05:01:12,488 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:01:13,002 - train.py[line:120] - INFO: Train Epoch: 119 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:02:06,312 - train.py[line:120] - INFO: Train Epoch: 119 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:02:58,421 - train.py[line:120] - INFO: Train Epoch: 119 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:03:52,156 - train.py[line:120] - INFO: Train Epoch: 119 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:04:20,168 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:04:28,690 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 05:04:45,927 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:04:46,451 - train.py[line:120] - INFO: Train Epoch: 120 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:05:40,378 - train.py[line:120] - INFO: Train Epoch: 120 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:06:32,607 - train.py[line:120] - INFO: Train Epoch: 120 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:07:25,278 - train.py[line:120] - INFO: Train Epoch: 120 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:07:53,158 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:08:01,637 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 05:08:18,388 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:08:18,920 - train.py[line:120] - INFO: Train Epoch: 121 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:09:12,947 - train.py[line:120] - INFO: Train Epoch: 121 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:10:06,199 - train.py[line:120] - INFO: Train Epoch: 121 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:10:58,950 - train.py[line:120] - INFO: Train Epoch: 121 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:11:26,184 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:11:34,641 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3161e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:11:50,990 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3161e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:11:51,497 - train.py[line:120] - INFO: Train Epoch: 122 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:12:43,913 - train.py[line:120] - INFO: Train Epoch: 122 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:13:36,397 - train.py[line:120] - INFO: Train Epoch: 122 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:14:28,863 - train.py[line:120] - INFO: Train Epoch: 122 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:14:55,182 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:15:03,661 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 05:15:20,239 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:15:20,740 - train.py[line:120] - INFO: Train Epoch: 123 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:16:12,936 - train.py[line:120] - INFO: Train Epoch: 123 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:17:04,951 - train.py[line:120] - INFO: Train Epoch: 123 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:17:56,479 - train.py[line:120] - INFO: Train Epoch: 123 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:18:22,092 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:18:30,484 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:18:47,001 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:18:47,465 - train.py[line:120] - INFO: Train Epoch: 124 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:19:38,701 - train.py[line:120] - INFO: Train Epoch: 124 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:20:30,624 - train.py[line:120] - INFO: Train Epoch: 124 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:21:21,923 - train.py[line:120] - INFO: Train Epoch: 124 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:21:48,745 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:21:57,153 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3190e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 05:22:13,284 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3197e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:22:13,767 - train.py[line:120] - INFO: Train Epoch: 125 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:23:05,129 - train.py[line:120] - INFO: Train Epoch: 125 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:23:55,751 - train.py[line:120] - INFO: Train Epoch: 125 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:24:46,007 - train.py[line:120] - INFO: Train Epoch: 125 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:25:12,573 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:25:21,145 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3212e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:25:37,649 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:25:38,130 - train.py[line:120] - INFO: Train Epoch: 126 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:26:29,011 - train.py[line:120] - INFO: Train Epoch: 126 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:27:20,809 - train.py[line:120] - INFO: Train Epoch: 126 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:28:10,574 - train.py[line:120] - INFO: Train Epoch: 126 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:28:37,151 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:28:45,344 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3212e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:29:01,398 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:29:01,869 - train.py[line:120] - INFO: Train Epoch: 127 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:29:52,745 - train.py[line:120] - INFO: Train Epoch: 127 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:30:44,188 - train.py[line:120] - INFO: Train Epoch: 127 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:31:33,413 - train.py[line:120] - INFO: Train Epoch: 127 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:31:58,806 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:32:07,333 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 05:32:23,798 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:32:24,274 - train.py[line:120] - INFO: Train Epoch: 128 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:33:13,891 - train.py[line:120] - INFO: Train Epoch: 128 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:34:03,337 - train.py[line:120] - INFO: Train Epoch: 128 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:34:54,226 - train.py[line:120] - INFO: Train Epoch: 128 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:35:20,796 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:35:29,303 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3151e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:35:45,407 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3165e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:35:45,876 - train.py[line:120] - INFO: Train Epoch: 129 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:36:37,134 - train.py[line:120] - INFO: Train Epoch: 129 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:37:29,400 - train.py[line:120] - INFO: Train Epoch: 129 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:38:20,877 - train.py[line:120] - INFO: Train Epoch: 129 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:38:46,273 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:38:54,501 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3143e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:39:10,845 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3180e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:39:11,352 - train.py[line:120] - INFO: Train Epoch: 130 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:40:02,512 - train.py[line:120] - INFO: Train Epoch: 130 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:40:54,015 - train.py[line:120] - INFO: Train Epoch: 130 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:41:43,753 - train.py[line:120] - INFO: Train Epoch: 130 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:42:08,866 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:42:17,240 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 05:42:33,545 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:42:34,005 - train.py[line:120] - INFO: Train Epoch: 131 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:43:24,013 - train.py[line:120] - INFO: Train Epoch: 131 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:44:15,104 - train.py[line:120] - INFO: Train Epoch: 131 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:45:06,051 - train.py[line:120] - INFO: Train Epoch: 131 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:45:32,459 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:45:40,848 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 05:45:57,015 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:45:57,641 - train.py[line:120] - INFO: Train Epoch: 132 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:46:49,432 - train.py[line:120] - INFO: Train Epoch: 132 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:47:40,922 - train.py[line:120] - INFO: Train Epoch: 132 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:48:31,613 - train.py[line:120] - INFO: Train Epoch: 132 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:48:58,256 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:49:06,519 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 05:49:22,789 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:49:23,245 - train.py[line:120] - INFO: Train Epoch: 133 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:50:15,599 - train.py[line:120] - INFO: Train Epoch: 133 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:51:07,060 - train.py[line:120] - INFO: Train Epoch: 133 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:51:58,252 - train.py[line:120] - INFO: Train Epoch: 133 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:52:24,519 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:52:32,825 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 05:52:49,111 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:52:49,586 - train.py[line:120] - INFO: Train Epoch: 134 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:53:40,740 - train.py[line:120] - INFO: Train Epoch: 134 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:54:32,038 - train.py[line:120] - INFO: Train Epoch: 134 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:55:23,660 - train.py[line:120] - INFO: Train Epoch: 134 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:55:50,143 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:55:58,501 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3182e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 05:56:15,100 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3222e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:56:15,590 - train.py[line:120] - INFO: Train Epoch: 135 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:57:05,935 - train.py[line:120] - INFO: Train Epoch: 135 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:57:56,415 - train.py[line:120] - INFO: Train Epoch: 135 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:58:47,376 - train.py[line:120] - INFO: Train Epoch: 135 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 05:59:14,196 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 05:59:22,482 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3147e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 05:59:38,865 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3165e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 05:59:39,355 - train.py[line:120] - INFO: Train Epoch: 136 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:00:30,961 - train.py[line:120] - INFO: Train Epoch: 136 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:01:22,745 - train.py[line:120] - INFO: Train Epoch: 136 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:02:13,919 - train.py[line:120] - INFO: Train Epoch: 136 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:02:40,459 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:02:48,789 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:03:05,135 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:03:05,627 - train.py[line:120] - INFO: Train Epoch: 137 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:03:57,027 - train.py[line:120] - INFO: Train Epoch: 137 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:04:48,386 - train.py[line:120] - INFO: Train Epoch: 137 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:05:39,439 - train.py[line:120] - INFO: Train Epoch: 137 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:06:05,920 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:06:14,215 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 06:06:30,359 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:06:30,834 - train.py[line:120] - INFO: Train Epoch: 138 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:07:22,849 - train.py[line:120] - INFO: Train Epoch: 138 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:08:11,878 - train.py[line:120] - INFO: Train Epoch: 138 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:09:03,354 - train.py[line:120] - INFO: Train Epoch: 138 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:09:30,104 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:09:38,430 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3218e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 06:09:54,623 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3217e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:09:55,131 - train.py[line:120] - INFO: Train Epoch: 139 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:10:47,516 - train.py[line:120] - INFO: Train Epoch: 139 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:11:39,059 - train.py[line:120] - INFO: Train Epoch: 139 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:12:30,514 - train.py[line:120] - INFO: Train Epoch: 139 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:12:57,539 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:13:05,843 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 06:13:21,914 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:13:22,367 - train.py[line:120] - INFO: Train Epoch: 140 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:14:14,617 - train.py[line:120] - INFO: Train Epoch: 140 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:15:06,664 - train.py[line:120] - INFO: Train Epoch: 140 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:15:58,921 - train.py[line:120] - INFO: Train Epoch: 140 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:16:25,617 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:16:34,211 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3167e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:16:50,551 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3201e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:16:51,063 - train.py[line:120] - INFO: Train Epoch: 141 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:17:41,651 - train.py[line:120] - INFO: Train Epoch: 141 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:18:32,518 - train.py[line:120] - INFO: Train Epoch: 141 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:19:24,300 - train.py[line:120] - INFO: Train Epoch: 141 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:19:51,519 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:19:59,779 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 06:20:15,818 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3204e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:20:16,294 - train.py[line:120] - INFO: Train Epoch: 142 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:21:07,631 - train.py[line:120] - INFO: Train Epoch: 142 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:21:57,991 - train.py[line:120] - INFO: Train Epoch: 142 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:22:47,069 - train.py[line:120] - INFO: Train Epoch: 142 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:23:13,382 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:23:21,710 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3193e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 06:23:37,747 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3203e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:23:38,228 - train.py[line:120] - INFO: Train Epoch: 143 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:24:30,398 - train.py[line:120] - INFO: Train Epoch: 143 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:25:22,207 - train.py[line:120] - INFO: Train Epoch: 143 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:26:14,237 - train.py[line:120] - INFO: Train Epoch: 143 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:26:41,278 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:26:49,498 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3147e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 06:27:05,658 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3165e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:27:06,142 - train.py[line:120] - INFO: Train Epoch: 144 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:27:58,220 - train.py[line:120] - INFO: Train Epoch: 144 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:28:49,289 - train.py[line:120] - INFO: Train Epoch: 144 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:29:38,584 - train.py[line:120] - INFO: Train Epoch: 144 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:30:04,814 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:30:13,068 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:30:29,410 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:30:29,884 - train.py[line:120] - INFO: Train Epoch: 145 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:31:21,145 - train.py[line:120] - INFO: Train Epoch: 145 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:32:12,584 - train.py[line:120] - INFO: Train Epoch: 145 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:33:03,602 - train.py[line:120] - INFO: Train Epoch: 145 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:33:29,904 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:33:38,120 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3179e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:33:54,238 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3196e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:33:54,721 - train.py[line:120] - INFO: Train Epoch: 146 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:34:46,725 - train.py[line:120] - INFO: Train Epoch: 146 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:35:37,456 - train.py[line:120] - INFO: Train Epoch: 146 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:36:28,885 - train.py[line:120] - INFO: Train Epoch: 146 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:36:55,349 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:37:03,406 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3169e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 06:37:19,469 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3162e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:37:19,926 - train.py[line:120] - INFO: Train Epoch: 147 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:38:11,973 - train.py[line:120] - INFO: Train Epoch: 147 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:39:03,435 - train.py[line:120] - INFO: Train Epoch: 147 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:39:55,398 - train.py[line:120] - INFO: Train Epoch: 147 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:40:21,971 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:40:30,173 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3171e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:40:46,322 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3218e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:40:46,788 - train.py[line:120] - INFO: Train Epoch: 148 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:41:39,064 - train.py[line:120] - INFO: Train Epoch: 148 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:42:30,242 - train.py[line:120] - INFO: Train Epoch: 148 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:43:21,698 - train.py[line:120] - INFO: Train Epoch: 148 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:43:48,073 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:43:56,479 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:44:12,614 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:44:13,118 - train.py[line:120] - INFO: Train Epoch: 149 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:45:05,050 - train.py[line:120] - INFO: Train Epoch: 149 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:45:56,248 - train.py[line:120] - INFO: Train Epoch: 149 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:46:47,327 - train.py[line:120] - INFO: Train Epoch: 149 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:47:13,937 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:47:22,308 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3198e+00, Accuracy: 513/5000 (10.26%)
[0m
[38;21m2024-11-13 06:47:38,580 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3220e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (10.26): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:47:39,069 - train.py[line:120] - INFO: Train Epoch: 150 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:48:31,081 - train.py[line:120] - INFO: Train Epoch: 150 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:49:22,630 - train.py[line:120] - INFO: Train Epoch: 150 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:50:13,876 - train.py[line:120] - INFO: Train Epoch: 150 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:50:40,220 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:50:48,492 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3169e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 06:51:04,840 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3162e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:51:05,330 - train.py[line:120] - INFO: Train Epoch: 151 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:51:57,038 - train.py[line:120] - INFO: Train Epoch: 151 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:52:48,381 - train.py[line:120] - INFO: Train Epoch: 151 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:53:37,742 - train.py[line:120] - INFO: Train Epoch: 151 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:54:03,869 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:54:12,116 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3194e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 06:54:28,456 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3208e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:54:28,920 - train.py[line:120] - INFO: Train Epoch: 152 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:55:21,669 - train.py[line:120] - INFO: Train Epoch: 152 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:56:13,797 - train.py[line:120] - INFO: Train Epoch: 152 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:57:05,660 - train.py[line:120] - INFO: Train Epoch: 152 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:57:32,447 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 06:57:40,682 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3191e+00, Accuracy: 495/5000 (9.90%)
[0m
[38;21m2024-11-13 06:57:56,833 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3198e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.90): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 06:57:57,311 - train.py[line:120] - INFO: Train Epoch: 153 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:58:49,113 - train.py[line:120] - INFO: Train Epoch: 153 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 06:59:40,557 - train.py[line:120] - INFO: Train Epoch: 153 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:00:31,466 - train.py[line:120] - INFO: Train Epoch: 153 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:00:58,202 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:01:06,615 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:01:22,928 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:01:23,410 - train.py[line:120] - INFO: Train Epoch: 154 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:02:15,466 - train.py[line:120] - INFO: Train Epoch: 154 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:03:07,210 - train.py[line:120] - INFO: Train Epoch: 154 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:03:58,814 - train.py[line:120] - INFO: Train Epoch: 154 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:04:25,391 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:04:33,761 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:04:50,070 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:04:50,578 - train.py[line:120] - INFO: Train Epoch: 155 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:05:42,735 - train.py[line:120] - INFO: Train Epoch: 155 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:06:33,923 - train.py[line:120] - INFO: Train Epoch: 155 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:07:24,934 - train.py[line:120] - INFO: Train Epoch: 155 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:07:51,491 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:07:59,784 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:08:16,006 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:08:16,535 - train.py[line:120] - INFO: Train Epoch: 156 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:09:10,232 - train.py[line:120] - INFO: Train Epoch: 156 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:10:02,206 - train.py[line:120] - INFO: Train Epoch: 156 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:10:54,281 - train.py[line:120] - INFO: Train Epoch: 156 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:11:20,961 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:11:29,350 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:11:45,625 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:11:46,054 - train.py[line:120] - INFO: Train Epoch: 157 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:12:38,499 - train.py[line:120] - INFO: Train Epoch: 157 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:13:30,441 - train.py[line:120] - INFO: Train Epoch: 157 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:14:21,549 - train.py[line:120] - INFO: Train Epoch: 157 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:14:47,340 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:14:55,677 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:15:12,071 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:15:12,521 - train.py[line:120] - INFO: Train Epoch: 158 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:16:03,915 - train.py[line:120] - INFO: Train Epoch: 158 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:16:55,480 - train.py[line:120] - INFO: Train Epoch: 158 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:17:46,446 - train.py[line:120] - INFO: Train Epoch: 158 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:18:12,977 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:18:21,564 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:18:37,872 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:18:38,392 - train.py[line:120] - INFO: Train Epoch: 159 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:19:31,743 - train.py[line:120] - INFO: Train Epoch: 159 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:20:21,930 - train.py[line:120] - INFO: Train Epoch: 159 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:21:13,520 - train.py[line:120] - INFO: Train Epoch: 159 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:21:39,967 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:21:48,295 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:22:04,678 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:22:05,176 - train.py[line:120] - INFO: Train Epoch: 160 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:22:56,968 - train.py[line:120] - INFO: Train Epoch: 160 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:23:46,151 - train.py[line:120] - INFO: Train Epoch: 160 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:24:35,077 - train.py[line:120] - INFO: Train Epoch: 160 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:25:00,383 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:25:08,748 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:25:24,879 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:25:25,343 - train.py[line:120] - INFO: Train Epoch: 161 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:26:16,695 - train.py[line:120] - INFO: Train Epoch: 161 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:27:08,305 - train.py[line:120] - INFO: Train Epoch: 161 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:28:00,199 - train.py[line:120] - INFO: Train Epoch: 161 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:28:26,838 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:28:35,102 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:28:51,299 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:28:51,755 - train.py[line:120] - INFO: Train Epoch: 162 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:29:43,093 - train.py[line:120] - INFO: Train Epoch: 162 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:30:33,820 - train.py[line:120] - INFO: Train Epoch: 162 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:31:24,898 - train.py[line:120] - INFO: Train Epoch: 162 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:31:51,503 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:31:59,816 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:32:16,153 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:32:16,618 - train.py[line:120] - INFO: Train Epoch: 163 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:33:08,515 - train.py[line:120] - INFO: Train Epoch: 163 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:33:58,913 - train.py[line:120] - INFO: Train Epoch: 163 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:34:50,319 - train.py[line:120] - INFO: Train Epoch: 163 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:35:17,134 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:35:25,374 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:35:42,136 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:35:42,621 - train.py[line:120] - INFO: Train Epoch: 164 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:36:32,899 - train.py[line:120] - INFO: Train Epoch: 164 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:37:23,094 - train.py[line:120] - INFO: Train Epoch: 164 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:38:14,159 - train.py[line:120] - INFO: Train Epoch: 164 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:38:40,736 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:38:49,208 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:39:05,401 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:39:05,873 - train.py[line:120] - INFO: Train Epoch: 165 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:39:57,652 - train.py[line:120] - INFO: Train Epoch: 165 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:40:49,018 - train.py[line:120] - INFO: Train Epoch: 165 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:41:40,717 - train.py[line:120] - INFO: Train Epoch: 165 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:42:07,521 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:42:15,980 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:42:32,593 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:42:33,079 - train.py[line:120] - INFO: Train Epoch: 166 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:43:24,835 - train.py[line:120] - INFO: Train Epoch: 166 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:44:15,696 - train.py[line:120] - INFO: Train Epoch: 166 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:45:07,175 - train.py[line:120] - INFO: Train Epoch: 166 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:45:33,845 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:45:42,388 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:45:58,720 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:45:59,214 - train.py[line:120] - INFO: Train Epoch: 167 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:46:50,564 - train.py[line:120] - INFO: Train Epoch: 167 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:47:42,007 - train.py[line:120] - INFO: Train Epoch: 167 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:48:33,523 - train.py[line:120] - INFO: Train Epoch: 167 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:49:00,039 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:49:08,388 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:49:24,969 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:49:25,408 - train.py[line:120] - INFO: Train Epoch: 168 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:50:16,995 - train.py[line:120] - INFO: Train Epoch: 168 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:51:08,222 - train.py[line:120] - INFO: Train Epoch: 168 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:51:59,654 - train.py[line:120] - INFO: Train Epoch: 168 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:52:26,064 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:52:34,455 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:52:50,655 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:52:51,113 - train.py[line:120] - INFO: Train Epoch: 169 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:53:42,621 - train.py[line:120] - INFO: Train Epoch: 169 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:54:33,671 - train.py[line:120] - INFO: Train Epoch: 169 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:55:24,560 - train.py[line:120] - INFO: Train Epoch: 169 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:55:50,874 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:55:59,073 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:56:15,306 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:56:15,765 - train.py[line:120] - INFO: Train Epoch: 170 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:57:07,140 - train.py[line:120] - INFO: Train Epoch: 170 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:57:58,441 - train.py[line:120] - INFO: Train Epoch: 170 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:58:49,823 - train.py[line:120] - INFO: Train Epoch: 170 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 07:59:16,177 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 07:59:24,563 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 07:59:40,894 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 07:59:41,372 - train.py[line:120] - INFO: Train Epoch: 171 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:00:32,672 - train.py[line:120] - INFO: Train Epoch: 171 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:01:24,084 - train.py[line:120] - INFO: Train Epoch: 171 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:02:14,976 - train.py[line:120] - INFO: Train Epoch: 171 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:02:41,571 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:02:50,018 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:03:06,450 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:03:06,928 - train.py[line:120] - INFO: Train Epoch: 172 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:03:58,071 - train.py[line:120] - INFO: Train Epoch: 172 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:04:49,677 - train.py[line:120] - INFO: Train Epoch: 172 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:05:39,807 - train.py[line:120] - INFO: Train Epoch: 172 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:06:05,084 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:06:13,421 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:06:29,719 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:06:30,211 - train.py[line:120] - INFO: Train Epoch: 173 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:07:19,175 - train.py[line:120] - INFO: Train Epoch: 173 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:08:07,861 - train.py[line:120] - INFO: Train Epoch: 173 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:08:56,760 - train.py[line:120] - INFO: Train Epoch: 173 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:09:22,478 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:09:30,936 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:09:47,263 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:09:47,746 - train.py[line:120] - INFO: Train Epoch: 174 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:10:38,509 - train.py[line:120] - INFO: Train Epoch: 174 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:11:29,131 - train.py[line:120] - INFO: Train Epoch: 174 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:12:20,388 - train.py[line:120] - INFO: Train Epoch: 174 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:12:46,675 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:12:54,869 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:13:11,126 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:13:11,568 - train.py[line:120] - INFO: Train Epoch: 175 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:14:02,875 - train.py[line:120] - INFO: Train Epoch: 175 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:14:54,010 - train.py[line:120] - INFO: Train Epoch: 175 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:15:45,708 - train.py[line:120] - INFO: Train Epoch: 175 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:16:12,663 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:16:21,040 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:16:37,184 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:16:37,640 - train.py[line:120] - INFO: Train Epoch: 176 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:17:28,581 - train.py[line:120] - INFO: Train Epoch: 176 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:18:19,855 - train.py[line:120] - INFO: Train Epoch: 176 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:19:11,101 - train.py[line:120] - INFO: Train Epoch: 176 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:19:37,396 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:19:45,747 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:20:01,970 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:20:02,458 - train.py[line:120] - INFO: Train Epoch: 177 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:20:54,360 - train.py[line:120] - INFO: Train Epoch: 177 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:21:46,516 - train.py[line:120] - INFO: Train Epoch: 177 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:22:38,157 - train.py[line:120] - INFO: Train Epoch: 177 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:23:04,623 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:23:12,959 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:23:29,002 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:23:29,448 - train.py[line:120] - INFO: Train Epoch: 178 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:24:21,305 - train.py[line:120] - INFO: Train Epoch: 178 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:25:12,843 - train.py[line:120] - INFO: Train Epoch: 178 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:26:03,836 - train.py[line:120] - INFO: Train Epoch: 178 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:26:30,557 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:26:38,918 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:26:55,268 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:26:55,752 - train.py[line:120] - INFO: Train Epoch: 179 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:27:46,708 - train.py[line:120] - INFO: Train Epoch: 179 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:28:37,833 - train.py[line:120] - INFO: Train Epoch: 179 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:29:29,176 - train.py[line:120] - INFO: Train Epoch: 179 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:29:55,589 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:30:03,833 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:30:20,183 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:30:20,636 - train.py[line:120] - INFO: Train Epoch: 180 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:31:11,581 - train.py[line:120] - INFO: Train Epoch: 180 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:32:02,710 - train.py[line:120] - INFO: Train Epoch: 180 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:32:52,263 - train.py[line:120] - INFO: Train Epoch: 180 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:33:18,769 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:33:27,210 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:33:43,570 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:33:44,073 - train.py[line:120] - INFO: Train Epoch: 181 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:34:36,560 - train.py[line:120] - INFO: Train Epoch: 181 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:35:28,822 - train.py[line:120] - INFO: Train Epoch: 181 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:36:20,453 - train.py[line:120] - INFO: Train Epoch: 181 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:36:47,177 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:36:55,488 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:37:11,715 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:37:12,199 - train.py[line:120] - INFO: Train Epoch: 182 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:38:03,465 - train.py[line:120] - INFO: Train Epoch: 182 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:38:54,640 - train.py[line:120] - INFO: Train Epoch: 182 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:39:46,201 - train.py[line:120] - INFO: Train Epoch: 182 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:40:12,767 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:40:21,123 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:40:37,312 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:40:37,760 - train.py[line:120] - INFO: Train Epoch: 183 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:41:28,398 - train.py[line:120] - INFO: Train Epoch: 183 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:42:18,862 - train.py[line:120] - INFO: Train Epoch: 183 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:43:09,459 - train.py[line:120] - INFO: Train Epoch: 183 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:43:35,898 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:43:44,275 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:44:00,452 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:44:00,936 - train.py[line:120] - INFO: Train Epoch: 184 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:44:51,952 - train.py[line:120] - INFO: Train Epoch: 184 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:45:43,629 - train.py[line:120] - INFO: Train Epoch: 184 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:46:34,716 - train.py[line:120] - INFO: Train Epoch: 184 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:47:01,188 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:47:09,502 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:47:25,773 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:47:26,248 - train.py[line:120] - INFO: Train Epoch: 185 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:48:17,224 - train.py[line:120] - INFO: Train Epoch: 185 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:49:08,216 - train.py[line:120] - INFO: Train Epoch: 185 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:49:58,928 - train.py[line:120] - INFO: Train Epoch: 185 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:50:25,234 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:50:33,456 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:50:49,667 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:50:50,128 - train.py[line:120] - INFO: Train Epoch: 186 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:51:41,287 - train.py[line:120] - INFO: Train Epoch: 186 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:52:30,331 - train.py[line:120] - INFO: Train Epoch: 186 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:53:20,029 - train.py[line:120] - INFO: Train Epoch: 186 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:53:46,805 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:53:55,159 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:54:11,432 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:54:11,919 - train.py[line:120] - INFO: Train Epoch: 187 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:55:02,251 - train.py[line:120] - INFO: Train Epoch: 187 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:55:53,614 - train.py[line:120] - INFO: Train Epoch: 187 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:56:45,575 - train.py[line:120] - INFO: Train Epoch: 187 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:57:11,929 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 08:57:20,236 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 08:57:36,506 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 08:57:36,977 - train.py[line:120] - INFO: Train Epoch: 188 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:58:29,342 - train.py[line:120] - INFO: Train Epoch: 188 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 08:59:19,773 - train.py[line:120] - INFO: Train Epoch: 188 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:00:10,337 - train.py[line:120] - INFO: Train Epoch: 188 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:00:36,424 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:00:45,037 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:01:01,474 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:01:01,964 - train.py[line:120] - INFO: Train Epoch: 189 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:01:52,779 - train.py[line:120] - INFO: Train Epoch: 189 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:02:43,125 - train.py[line:120] - INFO: Train Epoch: 189 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:03:34,049 - train.py[line:120] - INFO: Train Epoch: 189 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:03:59,339 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:04:07,606 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:04:23,721 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:04:24,182 - train.py[line:120] - INFO: Train Epoch: 190 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:05:14,927 - train.py[line:120] - INFO: Train Epoch: 190 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:06:05,709 - train.py[line:120] - INFO: Train Epoch: 190 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:06:55,947 - train.py[line:120] - INFO: Train Epoch: 190 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:07:21,215 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:07:29,528 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:07:45,687 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:07:46,146 - train.py[line:120] - INFO: Train Epoch: 191 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:08:34,908 - train.py[line:120] - INFO: Train Epoch: 191 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:09:26,166 - train.py[line:120] - INFO: Train Epoch: 191 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:10:17,899 - train.py[line:120] - INFO: Train Epoch: 191 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:10:44,625 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:10:53,046 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:11:09,339 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:11:09,793 - train.py[line:120] - INFO: Train Epoch: 192 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:12:00,076 - train.py[line:120] - INFO: Train Epoch: 192 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:12:49,777 - train.py[line:120] - INFO: Train Epoch: 192 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:13:41,163 - train.py[line:120] - INFO: Train Epoch: 192 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:14:07,678 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:14:15,841 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:14:31,822 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:14:32,285 - train.py[line:120] - INFO: Train Epoch: 193 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:15:24,115 - train.py[line:120] - INFO: Train Epoch: 193 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:16:19,524 - train.py[line:120] - INFO: Train Epoch: 193 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:17:17,916 - train.py[line:120] - INFO: Train Epoch: 193 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:17:51,266 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:18:00,665 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:18:18,248 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:18:18,852 - train.py[line:120] - INFO: Train Epoch: 194 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:19:21,137 - train.py[line:120] - INFO: Train Epoch: 194 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:20:15,681 - train.py[line:120] - INFO: Train Epoch: 194 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:21:09,405 - train.py[line:120] - INFO: Train Epoch: 194 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:21:36,998 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:21:45,462 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:22:01,971 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:22:02,458 - train.py[line:120] - INFO: Train Epoch: 195 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:22:57,074 - train.py[line:120] - INFO: Train Epoch: 195 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:23:53,519 - train.py[line:120] - INFO: Train Epoch: 195 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:24:55,702 - train.py[line:120] - INFO: Train Epoch: 195 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:25:28,993 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:25:38,192 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:25:56,256 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:25:56,861 - train.py[line:120] - INFO: Train Epoch: 196 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:27:00,328 - train.py[line:120] - INFO: Train Epoch: 196 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:27:56,180 - train.py[line:120] - INFO: Train Epoch: 196 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:28:50,455 - train.py[line:120] - INFO: Train Epoch: 196 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:29:18,794 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:29:27,118 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:29:43,732 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:29:44,200 - train.py[line:120] - INFO: Train Epoch: 197 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:30:39,109 - train.py[line:120] - INFO: Train Epoch: 197 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:31:33,041 - train.py[line:120] - INFO: Train Epoch: 197 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:32:32,409 - train.py[line:120] - INFO: Train Epoch: 197 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:33:04,727 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:33:13,792 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:33:31,674 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:33:32,208 - train.py[line:120] - INFO: Train Epoch: 198 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:34:33,815 - train.py[line:120] - INFO: Train Epoch: 198 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:35:30,108 - train.py[line:120] - INFO: Train Epoch: 198 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:36:23,365 - train.py[line:120] - INFO: Train Epoch: 198 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:36:50,938 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:36:59,196 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:37:15,636 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:37:16,115 - train.py[line:120] - INFO: Train Epoch: 199 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:38:09,443 - train.py[line:120] - INFO: Train Epoch: 199 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:39:03,322 - train.py[line:120] - INFO: Train Epoch: 199 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:40:03,341 - train.py[line:120] - INFO: Train Epoch: 199 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:40:34,114 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:40:42,896 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:41:00,419 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
[38;21m2024-11-13 09:41:00,940 - train.py[line:120] - INFO: Train Epoch: 200 [     64/  45000 (  0%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:42:02,194 - train.py[line:120] - INFO: Train Epoch: 200 [  12864/  45000 ( 29%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:42:58,957 - train.py[line:120] - INFO: Train Epoch: 200 [  25664/  45000 ( 57%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:43:52,175 - train.py[line:120] - INFO: Train Epoch: 200 [  38464/  45000 ( 85%)] Loss: 2.3026e+00 class Loss: 2.3026e+00[0m
[38;21m2024-11-13 09:44:20,576 - train.py[line:132] - INFO: Train class Loss: 2.3026e+00, Accuracy: 4501/45000 (10.00%)[0m
[38;21m2024-11-13 09:44:29,268 - train.py[line:178] - INFO: 
Validation set: Average loss: 2.3129e+00, Accuracy: 474/5000 (9.48%)
[0m
[38;21m2024-11-13 09:44:45,629 - train.py[line:220] - INFO: 
Test set: Average loss: 2.3106e+00, Accuracy: 1000/10000 (10.00%)
[0m
[I] Not best 3: [(44.46, 3), (40.16, 2), (30.98, 1)], skip this model (9.48): ./checkpoint/cifar10/qmobileViTMoE/train/QMobileViT_lr-0.0020_wb-8_run-1.pt
